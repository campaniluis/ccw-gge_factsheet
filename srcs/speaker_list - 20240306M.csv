Speaker,Time,Date,Duration,Statement,Region,High Contracting Party
FRANCE,10:24:06,2024-03-06,0:08:16,"I am just looking at France because I see a plaque , would you like on that topic or is it more general ? Okay . You have the floor on that . Thank you . I wanted to come back to the two points that you identified under point 2 with regard to international humanitarian law and come back to the subjects which were raised yesterday . First of all , we should like to recall under the first tier of the two - tier approach which should be banned or prohibited so for us systems that operate outside any kind of human control and the responsible chains of command . Those are the two points that you identified . But also the systems that would be classified as indiscriminate , so point 3 and those which may cause superfluous injury or unnecessary suffering . That is point 8 . In 3 we can identify a number of subcategories and this is where we would have the various subcategories that were identified by Delegations yesterday and especially point 4 , I will go to English , and point 6 , incapable of complying with the principle of distinction . So these are indeed subcategories within the prohibition for indiscriminate systems under point 3 . Another comment on point 9 , we understand the sense of what the United States Delegation said with regard to clarifying international , applicable international law because , of course , all states are not subject to the same conventional law . And then I should like to make a comment on two points which were also raised by other Delegations yesterday . First of all , on 5 , a number of Delegations raised the fact that this point , so are designed to target humans directly did not seem to be ideally worded because under international humanitarian law , certain military targets as well as combatants may be legitimate targets . So our Delegation endorses that interpretation of international humanitarian law which allows the targeting of military legitimate military targets that may sometimes be human beings . So that does not at all limit the fact that individuals and objects protected by international humanitarian law and under international humanitarian law cannot be targeted by these systems . A second comment on 11 , on responsibility , we agree with the general idea whether it be human or state responsibility and that should be guaranteed in cases of violation of IHL committed by these same weapon systems . So individual or state responsibility in the case of violation of IHL . Having said this , we should like to see greater clarifications or precision on the terms attribution . So that is a subject which may be subject to discussions in more depth . Coming back to what you raised at the beginning of the meeting , so the second point under this second question , which has to do with compliance of laws with IHL . Now , the way in which this question was formulated I think perfectly illustrates how the illicit nature of the use of certain weapon systems which are not prohibited would be subject to context . So as you said , the context must be taken into account when examining this . And if we are prohibiting systems which are completely autonomous and , therefore , incapable of respecting international humanitarian law , we think that other systems which include autonomy could be employed in agreement with international laws as we mentioned yesterday . And so that should be determined according to their characteristics , their capacity , and their context of use . And in order to guarantee the compatibility with IHL , other measures may be implemented by states which , as we see it , would form the second tier of that two - tier approach . Just to give some clarifications without wanting to go into too much detail , for example , our Delegation considers that the assessments are crucial to find out whether the use of these systems which fulfill that autonomy would be prohibited in any circumstances or whether this would only be under certain circumstances . And those legal reviews would be based on the capacities of the systems themselves but also on their environment and predicted environment . So the capacity of the system within that specific environment is crucial because that would allow the determination of what circumstances may be used in agreement with international humanitarian law so that would allow the effects and the effects to be known in a specific operational environment . And also human control is essential in order to guarantee the compliance of these systems with international humanitarian law . And in order to determine which specific measures the human would have to take and to take the more or less extended degree of control , this will be necessary to take into account . Once again , it is the context , the capacity , the kind of target or indeed the mission which would be some of the essential criteria . So what we would really like to highlight , Chair , is that if the legal or illegal nature of these systems under humanitarian law can be properly identified , that is the second part of the two - tier approach . We should not forget that international humanitarian law is a realistic law which does look to guarantee a balance at all times between necessity in terms of military needs and humanitarian aspects . So , for example , if we look at the principle of proportionality with the determination of the military advantage and collateral damage are implemented and inextricably linked to the context as is the case for weapon systems . Indeed , certain weapon systems may not be lawfully used in a specific case but may be the opposite in other situations . So I think I have made my point quite clear . That is why we consider that human control is essential in order to take into account the appropriate measures in order to define the context of use of the system , to guarantee that it is used lawfully , but also to ensure responsibility in case of violation of international humanitarian law . And I will stop there . Thank you very much , Chair .",Western European and other States,Yes
AUSTRALIA,10:32:48,2024-03-06,0:07:18,"Thank you , Chair . Having made some broad comments yesterday on the framing and structure of this discussion on part 1 of topic 2 , we would like to make some specific comments on several bullet points . Turning to the first set of elements , I may wish to put the document back on the screen to help guide the discussion . The first point we would like to make is that the concepts of human control sorry . Thank you . So turning to the first set of elements , the first point we would like to make is that the concepts of human control or meaningful human control are not terms found in existing IHL . Australia's concerns with terminology like meaningful human control are well known . We consider this phrase vague and subject to differing interpretations and therefore not overly helpful in clarifying how IHL applies to laws or giving concrete guidance to states on how to ensure compliance with IHL . A weapon will always be a tool rather than a replacement for a human . The idea of a weapon system operating in the absence of any human involvement or control or what some Delegations describe as fully autonomous weapon systems is also somewhat implausible from our perspective , since a human will always be involved in programming , activating or setting parameters for the weapon system . Regarding how we conceptualize human control and involvement in the context of the two - tier approach , we note that IHL addresses the legality of weapons in two ways . Firstly , it prohibits types of weapons based on intrinsic characteristics and effects and secondly , it restricts certain uses of otherwise lawful weapons . We think the notion of weapon systems being outside human control goes to the manner in which it is used rather than any intrinsic quality of the weapon system and are therefore best addressed as a regulatory issue in Tier 2 . Turning to the second part of this bullet point , operating outside a responsible chain of command as an element making a laws incompatible with IHL , once again we think this element as described in this paper goes to how a weapon system is used and is best dealt with in Tier 2 . We agree with the proposition that laws should only be deployed and operated within a responsible chain of human command and control and this idea is reflected in draft Article 6.1C of our joint proposal as a regulatory measure to ensure accountability . We now turn to bullet point 3 which states that laws would be incompatible with IHL if they are inherently indiscriminate . Australia agrees that IHL prohibits the use of laws that are inherently indiscriminate and supports including a reference to this prohibition under Tier 1 relating to inherent design features . Bullet point 4 states that laws would be inherently incompatible with IHL if it cannot be directed at a specific military objective . A question here arises as to what is meant by the phrase specific military objective . As was noted yesterday not all weapons are strictly speaking launched at a specific target . They could actually be launched at a group of specific military objectives without knowing which one would be hit . Target . We note that the term target after the word civilians in that phrase should not be placed here either . Intentionally directing attacks against civilians and civilian objects is prohibited under IHL . As to the next point , we do not agree that laws would be incompatible with IHL if used to target humans directly . As noted by several other states yesterday and today , there is no general prohibition of this nature in existing IHL . Whether or not a weapon system could be lawfully used for antipersonnel purposes would depend on the capabilities and effects of the system and the circumstances of its use . Coming to the next bullet point , the principles of proportionality , distinction and feasible precautions in attack are targeting rules . Here we echo a point made by several Delegations yesterday that IHL principles being referred to here apply to the use of weapons rather than the weapon system itself . Thus , it would be more appropriate to say that laws would be incompatible with IHL if they are , quote , incompatible of being used in compliance with the principles of distinction , proportionality and precaution . With respect to the next dot point , we agree with this in the sense that autonomous weapons may only be developed and used if their effects in attacks are able to be anticipated and controlled as required in the circumstances of use by IHL . Terms such as understood , explainable , understandable and traceable do not have an agreed meaning or a clear basis in IHL . However , we are interested in hearing others' views on how these terms are relevant to IHL compliance or application . For the next dot point , we would note that IHL prohibits an autonomous weapon system that is of a nature to cause superfluous injury or unnecessary suffering and would suggest the inclusion of those words . With respect to the next dot point , we consider that both alternatives would be workable from our perspective . And finally , on the last point on attribution , generally speaking , this point is about accountability . We agree with the idea that our laws must be used within a responsible human chain of command and control . But the question of attribution is probably in our view best dealt with in a discussion on accountability . Thank you .",Western European and other States,Yes
RUSSIAN FEDERATION,10:40:37,2024-03-06,0:10:21,"We will then try to facilitate you . Thank you very much . Thank you very much , Distinguished Chair . We would like to make some comments on the question that we now see on the screen . Now , turning to the question itself , as we see it , the essence of the question , if we do not really start trying to analyze the language that we see here , the question is an attempt to help Delegations during their consideration of the question of ensuring human control as a certain set of limitations that will be imposed on lethal autonomous weapons systems . So here the question of human control in this context is divided into two parts . The first part relates to existing norms and principles of IHL that relate to the need to ensure such human control , and this is done in a general way . And the second part relates to specific measures that make it possible to ensure such human control and the realization and compliance in the correct way with existing principles of IHL related to such human control for all weapon systems , specifically as it relates to laws . Now , if we look at the first part of this question , so one of the important elements of limitations is what we see , the need to ensure limitations on human control through the intervention of a human operator or the system of management at a higher level in order to change the regime of the functioning of such systems , including partial or full deactivation . And in all of that , we still continue to believe that in light of the responsibilities that states have and the responsibilities that individuals have in terms of the design and employment of weapon systems , the specific methods and forms of human control have to be left up to states to determine and decide . And in all of this , such human control should not necessarily be imposed through direct control , direct management . Now , if we look at the second part of this question and try to in a general way determine specific means and measures of ensuring such control , then some of these measures have already been reflected in last year's report of the GGE in paragraph 22 , and I am referring to limitations in terms of types of targets , limitations related to the duration of the function geographical scope and scale of the use , and also in terms of the participation in the control or management of individuals that have successfully acquired the skills for using such lethal autonomous weapon systems . Now , in addition to that , we also would like to propose to consider such methods of ensuring human control as increasing the reliability of weapon systems and their failure rate , the timely intervention and deactivation , carrying out tests of lethal autonomous weapon systems in realistic operational conditions , control of the process of manufacturing of separate elements and the device as a whole , as well as monitoring of pre-sorting and use disposal of certain elements and the device as a whole . I would once again like to especially stress the point that we are only talking about such methods methods in a general way . Specific forms of ensuring such human control through such methods should be left up to states to decide . Now , these proposals , these considerations have been reflected in the concept note , the functioning of the armed forces of the Russian federations in the employment and use of weapon systems with the use of artificial intelligence that was adopted in 2022 . This is , indeed , the main set of guidance for our country and for our Delegation . As we discuss questions related to human control , as one of the ways of placing limitations on the functioning of lethal autonomous weapon systems in the context of international humanitarian law , this is why we believe that through such methods or we should , in fact , be guided by such methods as we discuss this question . And now as far as the bullet points are concerned , the bullet points that we see on the screen , once again , we would like to make just a general comment without going into any details because most of these bullet points either simply reproduces the principles or norms of international humanitarian law that already have been functioning correctly in terms of all types of weapon systems . And in all of this , what we find to be a pretty dangerous trend is we see that there is a partial attempt to revise existing principles of IHL through amending or rewriting the specific language that were that was already adopted by states . Now , the second set of bullet points has already been enshrined in the conclusions and understandings of this GGG as reflected in the reports of the group for previous years and as an example , I already referred to the report of last year and specifically paragraph 22 and the remaining bullet points are either a very loose interpretation of international humanitarian law or they represent some general points that really do not have any legal force and could hardly be used by us as we continue our discussions and try to come up with some clear understandings related to the measures that can be applied to laws in the context of compliance with international law and international humanitarian law . Thank you .",Eastern European States,Yes
SWITZERLAND,10:51:21,2024-03-06,0:11:56,"I would like to give the floor to the Swiss Delegation . Thank you , Mr. Chair . We had a good discussion in the first two days and it is great to see that we are keeping that up . The questions on the screen on your second exactly those on your second question bring us to the core of a future instrument . The first here discussed mostly yesterday is the tip of the iceberg , so to speak , that would explicitly prohibit autonomous weapons because they could not be used in compliance with IHL or respecting ethical and other concerns . The second here now discussed focuses on the types of systems for which high contracting parties commit to take the necessary measures to ensure compliance with international law and where specific measures are spelled out . Mr. Chair , with regard to your overarching question , let me first start with a simple answer . Yes , it really depends on the specific context whether a system complies with IHL . Let me at the outset elaborate a few basic points that are pertinent and to capture what is necessary for IHL compliance . If an autonomous weapon system is not per se prohibited in all or certain circumstances , its use must be in compliance with the relevant rules and principles of IHL in hostilities , this is notably the principles of distinction , proportionality and precautions . The legality of the use of an autonomous weapon system in an attack depends on the circumstances and the context of that attack . The principle of distinction is one of the cornerstones of IHL and applies also to the use of autonomous weapon systems . The parties to the conflict shall direct their military operations only against military objectives , thus they must distinguish at all times between civilians and combatants as well as between civilian objects and military objectives . Attacks may only be directed against competence or military objectives . Attacking persons who are recognizing as order combat is prohibited . In case of doubt , civilian status must be presumed . The principle of proportionality requires that parties when attacking military objectives evaluate whether an attack may be expected to cause incidental loss of civilian life , injury to civilians , damage to civilian objects or a combination thereof which would be excessive in relation to the concrete and direct military advantage , anticipate and refrain from such prohibited attacks . And the principle of precaution requires that parties take constant care in the conduct of military operations to spare the civilian population , civilians and civilian objects and take all feasible precaution in the attack to avoid and in any event minimize incidental harm . Precautionary measures apply to all phases of a military operation from its planning to the decision to go ahead with the operation as well as during its execution and must be taken independently of the question of proportionality . The obligation to take steps to avoid and in any event minimize incidental harm applies regardless of whether the expected incidental harm would otherwise be excessive . In this sense , the risk of the harmful effects and the potential damage that could be caused beyond the targeted objective by an autonomous weapon system must be assessed with a degree of reasonable foreseeability . In addition , those who plan or decide upon an attack using an autonomous weapon system shall do everything feasible to verify that the objectives to be attacked are neither civilians nor civilian objects and that they are not subject to special protection . The assessment of these rules and principles of IHL governing hostilities depends on the context , the reasonably available information and the functioning of the weapon system . These points highlight that as for any system , IHL is a very high bar to meet . Compliance with these rules and principles is not a given . States and parties to an armed conflict must take measures to implement IHL . They must give orders and instructions to ensure observance of IHL and supervise their execution . Such measures are also important in relation to autonomous weapons . In addition , further restriction on how autonomous weapons are used are needed and measures are necessary to meet that high bar set by international humanitarian law . Now allow me to add a number of elements on the specific points on the screen . On the first sentence , the legality of laws depends on , we agree in principle , but would rather say that legality depends on compliance with the law and to do so , human control involvement alongside with other measures are necessary . Human control is not an absolute value , nor is it an abstract concept . Rather , human control is a specific tool and the specific type of control needed depends on situational factors . And this brings me to the first bullet , the operational context , the characteristics and capabilities of autonomous weapons as well as the anticipated targets all matter and influence the determination whether the use of an autonomous weapon in an attack complies with IHL . On the third bullet , point on human control , the starting point is that autonomous weapons must operate in compliance with international law and within a framework that ensures a sufficient degree of and a type of human control over the entire life cycle of a weapon system . This is vitally important because when using an autonomous weapon system , as with any weapon system , it is humans who must ensure legal conformity and in particular compliance with IHL under all circumstances . This is why the role of humans in the use of autonomous weapon systems has emerged as the central element in ensuring compliance with IHL . And moreover , we now have a shared understanding that certain degree of control over the use of force is not only necessary to comply with IHL but it is also important from an operational perspective and in terms of ethical accessibility . For a long time , we had quite intense discussions about terminology . We are of the view that last year we reached a point where differences in mere terminology carry less weight , whether we call it human machine interaction , human judgment , human involvement or whatever objective we put in front of human control . We think this is a good starting point to now shift discussions from terminology to concrete and operational concepts of control or involvement . What stands at the center is really the idea that humans must take measures at different stages in the life cycle of a weapon including in the engagement of autonomous weapon systems and understand their functioning in appropriate ways . On the fourth bullet point , control over the life cycle throughout the life cycle and at various points in the life cycle , this should not be too rigid but we agree in principle that different points offer themselves for control . We continue to believe that the famous sunset diagram is very helpful pointing to the different points in the life cycle where control measures can be taken and are useful . Having said that , one aspect is crucial . It should be clear that the moment of use of an autonomous weapon system is an eminently important point for human control . On the fifth bullet point on the ability of the operator , I would like to touch upon different aspects . We particularly like the notion that human operation must be able to . That is what we want to see in a two - tier discussion . But he or she must not only be able to limit the operation , predict outcomes and make informed decisions . These are elements that an operator must actually do in order to ensure that outcomes are lawful . A future instrument should therefore contain provisions in which high contracting parties commit to take the necessary measures to ensure lawful outcomes and IHL compliance . We also support what follows . Limitation regarding space and time as well as the phrase to limit types of targets , durations of operation , geographic scope and scale of use , those are important measures and we had a good discussion in the last year's GG session and even managed to validate some of these in the final report . Finally , on the last bullet , it would be helpful to have more clarity and a better understanding of the concepts and their interplay with IHL , notably of due diligence and good faith . Thank you very much .",Western European and other States,Yes
SINGAPORE,11:03:40,2024-03-06,0:01:40,"Distinguished Chair , thank you again for your excellent stewardship of this group . We find this modality of discussions particularly useful for stakeholders to constructively engage on the issue at hand . On the question , our Delegation finds resonance with the view that IHL compliance depends on the use of laws in a specific context rather than on the nature of the technology used in laws . But what the Distinguished Delegate from Switzerland has said , obviously , the specific context matters . From the compilation of replies to the Chair's guiding questions , we find the following three submissions particularly illuminating . First , the submission by our colleagues from Germany which stated that IHL rules are only triggered by concrete effects of the use of a weapon . In essence , that IHL is an effects - based law . Next , the submission by our colleagues from Brazil which stated that the legality of the use of laws is not determined by inherent features alone but significantly depends on the mode of use and functioning within specific context . This approach recognizes that the same technology may be used in compliance with IHL under certain conditions and violated under others . And third , the submission by our colleagues from the Republic of Korea which stated that compatibility with IHL cannot be defined by purely technical characteristics nor level of autonomy of laws . So with that , we hope that the discussion today could be focused on the specific context regarding the use of laws so as to ensure compliance to the key IHL principles of distinction , proportionality and precautions in attack . Thank you .",Asia-Pacific States,Yes
AUSTRIA,11:05:37,2024-03-06,0:07:34,"We are happy to continue the discussion on a new question today . We at the outset we might want to remark that we see this question very much related to the one that we have discussed yesterday and some of the comments that we made also on the structuring and on the tiers is valid here as well but I will come to that . I think the first thing that I want to announce is that our working paper has now been published and we are apologizing for the delay and encourage all colleagues to have a look at it . It has elements from our last year's working paper but also some new parts and this is structured in a way that we think is useful for our discussion today . What we also have done is that we have structured them as elements which could be for our future discussions here in this room a way on how we could go forward in discussing one of these elements one after the other . Of course , they are closely linked to each other as well . What we also have mentioned at the beginning of our working paper and this is a point that also the Russian Federation has made is that when we talk about the question that is at hand here , we have already made some progress last year , especially when it comes to limitations and control . This has been a part of the report in para 21C and para 22 and I think from how the discussions went last year there is I believe at least a willingness in this room to give those elements more flesh to the bone and this is something we definitely should do this year and I also see some willingness to do this already in the discussion . Then the question of the tiers for us , what we are seeing here on the screen is not necessarily the second tier . Many of this is also relating to the first tier and as I mentioned yesterday , this has to do with the concept of meaningful human control . As we also have outlined in our working paper , if there is an absence of meaningful human control or if a weapon systems cannot meet the requirement of meaningful human control , it should also be prohibited . But as I also said yesterday , this should be not a standalone provision . It should have some more specifications how this meaningful human control can be achieved and here we are also offering some possibilities . Interestingly enough , these possibilities or these requirements , conditions that could be met are those that we have already discussed in the GG laws and it also includes the limitations that may be required to set with regard to the duration geographical area , number of engagements and the types of targets , some of these elements that we have in the report from last year , an assessment of the context which we also have here on the screen and a functional understanding and this is something that is maybe missing among these elements that we are having here . We give in the different elements in our working paper , we are explaining those different elements of human control a little bit more in detail but this is how we see it . So this means that what we are having here on the screen has indirect relations to the prohibitions under tier number 1 and then something that is also hugely important is that we keep in mind the difference between the use and design . We need prohibitions for those kind of weapon systems that are already designed in a way that they cannot comply with IHL but as already mentioned , there is also the matter of use . If they cannot be used in a manner that complies with IHL or that they have specific features that would make them mostly usable in such a way . Sorry for being so complicated . On the issue of IHL , I think also if we look at the screen here , we have to emphasize again that what we are doing here is not just interpreting IHL . We are not specifying IHL . We are also doing we are also trying to create new law . So these three different elements that we have mentioned yesterday with the question is also valid here and we should keep that in mind . On the issue of context , which is highly interesting , we are having a rather long formulation but we think it is very useful . This is the selecting and applying force to the target and here we are also offering sorry for going back to this another formulation , alternative formulation to the human operator . We would suggest to use those authorizing any use of a weapons system that integrates autonomy in its critical functions . We believe this to be more specific but at the same time also more open . We had a discussion in the definitions part about the operator , the human operator , but authorizing any use of a weapons system takes into account also the questions of accountability but still indicates a certain closeness to the still indicates a certain closeness to the act . So this is important to us and also with the critical functions we are solving some of the problems of our discussion about functions of autonomous weapon systems that are not necessarily deadly or are creating problems with IHL . Back to the context , for us it is important that those authorizing any use must adequately assess the context in which the system is to be used . This means also this is a use factor . It is not something that needs to be in the design of the weapon systems but it is something that has to be taken into account when the weapon systems is used by the operator and the machine must be designed in a way that this is possible . More detail in the working paper . I am sorry otherwise I will be too long . Then we are also giving a little bit more detail on the limitations . We have those aspects already widely discussed and also in last year's working paper , geographical area , duration , types of targets . This is important so that the operator can make informed judgments about the anticipated outcomes of the use of force in accordance with legal obligations . This is also something that we have not spelled out in the report of last year but something that could be useful . And another important part is that those authorizing any use must be in a position to readjust , interrupt or deactivate a system if continued functioning would place it outside the context for which such informed legal judgments were made . I think I will leave it at that . There is a few other points that are also relating to this questions and this part of our discussions but I also would encourage colleagues once again to have a look at the working paper which has a little bit more than I just presented . Thank you .",Western European and other States,Yes
PERU,11:13:43,2024-03-06,0:03:01,"Peru first . Sorry . You have the floor . Thank you , Mr. Chair . I should like to start by reiterating my Delegation's support for the very focused way in which you have been directing the work of our group of experts which has allowed for significant exchange of ideas on some substantive topics . In this context , whilst reiterating the need to continue with the codification and progressive development of laws and standards on an international level which are applicable to armed conflicts , I should like to recall that Peru , together with other states , submitted a draft protocol on autonomous weapons systems , Protocol No. 6 , as can be seen in that document and in relation to the topics which are currently under discussion on what the legality of the laws depends on , Peru considers with regard to bullet point No. 3 that we prefer mention to the expression "" human control "" or "" meaningful human control "" as a preference . This refers to maintaining human actions and their preservation of a judgment and human intervention over and above the use of force . This , amongst other aspects , includes the following elements : One , the capacity to redefine or amend the objectives or missions of the weapons system or to adapt it in another way to the context , to deactivate , to abort or to terminate or to interrupt their functioning and use as necessary and to limit their function of auto initiation . Secondly , the capacity to limit the scope and the scale of use of the weapons system , including in terms of time and space , and to restrict their parameters and capacity to select objectives . So that means the capacity to select . Thirdly , the capacity to understand and explain the functioning of the weapons system , looking to be able to provide a retrospective explanation which would satisfy legal and other types of requirements relating to the functioning of the weapons system , including attribution of responsibility and accountability . Thank you very much .",Latin American and Caribbean States,Yes
ISRAEL,11:16:56,2024-03-06,0:04:06,"Thank you , Mr. Chair . Under IHL , the use of weapons systems that are not categorically prohibited under the existing rules applicable to the legality per se of weapons , which we referred to yesterday , would be governed by IHL rules that apply to the conduct of hostilities and in particular the targeting rules of IHL . As mentioned by France , Switzerland and others , assessing compliance with targeting law is done in a case - by - case assessment . Such an assessment needs to consider whether the use of the system in question is capable of complying with these rules in the expected circumstance of use . Therefore , there are three interdependent aspects for assessing the implementation of relevant IHL rules . First , the technical characteristics and capabilities of a weapons system . Second , the human element . And third , the operational context . To comprehensively assess the legalities of laws , it is crucial to consider all three aspects together . As mentioned by Australia , the human element or human involvement is integrated at various stages of the life cycle of weapons systems . Consideration of the three aspects needs to provide sufficient assurance that the employment of the weapons system would be in conformity with applicable law , rules of engagement and the intentions of its users . The appropriate degree of foreseeability and predictability of the weapons operation as well as the type and level of human machine interaction will be determined by the characteristics and capabilities of the particular system in question in view of the operational circumstances and the mission's requirements . In any event , as we stressed yesterday , aspects such as foreseeability and predictability as well as real - time human involvement in the system's operation are not in and of themselves IHL requirements but rather practical aspects which are relevant when assessing how to comply with IHL rules together with other factors . As mentioned , there is no one size fits all set of requirements that every weapons system needs to meet but rather these requirements may be adapted appropriately while considering the three aspects mentioned above , the weapon , the human and the operational context . Similarly , limits on aspects such as space and time of operation necessarily differ between different cases . Another point we wish to address pertains to the suggestion to distinguish between different types of military objectives . There is no basis in IHL to support the argument that objects meeting the definition of military objectives in accordance with IHL should as a matter of principle be treated differently in the context of employing laws . We believe that examining on a case - by - case basis the system's technological capabilities and its operational context will be useful in determining the lawful use of a particular weapon system in a specific operation to assert certain type of targets or another . To conclude , the components we deem appropriate for a case - by - case determination of a weapon system legality in its use encompass the particular weapon systems inherent characteristics and capabilities , the type and level of human input during the various stages of its life cycle and the operational context in which it is deployed . We do encourage further elaboration on the relation between these three component in our future deliberation on the legal aspects of laws . I thank you , Chair .",Western European and other States,Yes
JAPAN,11:21:16,2024-03-06,0:03:48,"Thank you , Mr. Chairperson . With regard to the guiding questions , the second guiding questions which is on the screen , I think we understood that this question is indeed to promote a common understanding of how regulation based on IHL should be in the concrete manner . This is understood that the aim of the question is to operationalize the second tier of the two - tier approach . In order to do it , it is better to discuss contents or concrete means rather than languages or concepts . Also as the Australian Delegation stated , the elements you put are somehow mixed covering also what we discussed yesterday . Therefore , this time allow me to explain our positions in this regard on the second tier of the two - tier approach without commenting on your bullet . To ensure compliance with international law , including international humanitarian law , we need to consider not only the use but also the entire life cycle of weapon systems based on emerging technologies in the area of laws . In this regard , it is important to improve the predictability and reliability of the use of autonomous weapon systems through repeated and rigorous testing , evaluation and verification of the hardware and software , especially during the design , development and testing phases , taking into account various realistic situations in order to assess the possible risks posed by such weapon systems and their mitigation measures . In light of the above , there is a need to further discuss and clarify application of IHL to each weapon system using emerging technologies independently in order to ensure compliance with IHL . In particular , the requirements for the application of IHL in the following areas can be further discussed . Decision support tools for commanders and operators and weapon systems that rely on autonomous functions for target selection and engagement , et cetera . Our draft Article's joint proposal , our joint proposal , the proposal reflecting this idea and mentioning the next points for compliance with IHL . We welcome the discussion on these points further . And finally , as again , Australian Delegation stated , our discussion should aim to build upon the past agreement . Last year , we agreed on the language on the second tier of the two - tier approach in Paragraph 22 . We should also have a chance to further deepen the discussion on the language to make it operational . Thank you .",Asia-Pacific States,Yes
PAKISTAN,11:25:17,2024-03-06,0:08:08,"Thank you , Chair . We would also like to contribute some general remarks and some of the bullet points that are on the screen . We second what has been said by our Distinguished Colleague from Austria in terms of how we see the second tier . The bullets that are here in front of the screen under this question , we do believe that many of these would contribute to the development of second tier that we will undertake . However , some of them could also go to the first tier . In addition , some other principles which are currently not reflected on the screen which are part of various proposals that have been presented in the past , they can also be included in this second tier . Having said that , I would like to just briefly react on some of the discussions that have taken place regarding the use of laws in compliance with the IHL . We do agree with the notion that the compliance with IHL and the rules that have been stated time and again , they are largely linked with the use of weapon systems . So the compliance is established during the use . Perhaps for this very reason , in our last year's report , we said it very clearly that the weapon systems which are incapable of being used with the IHL should not be used . However , at the same time , we have been having discussions that the IHL does apply fully both to the development and the use of laws and it is essentially our first guiding principle that we agreed in 2019 . So we would argue that those weapon systems which are incapable of being used in compliance with the IHL should not be developed and used if they have some inherent design - related characteristics which would render in compliance at the time of their use . So this notion I think has been brought up in our previous discussions as well . Then on the bullet points that are on the screen , firstly on the restriction of targets , duration of operation , geographic scope , we do note as outlined by other Delegates before me that some of these principles we were able to include for the first time in Paragraph 22 of our last year's report which was a very welcome development . At the same time , it is important to note that the language that was contained in that we came to the conclusion as a result of compromise also contained many caveats like as necessary we would need the states would need to establish themselves the limits . It is important that going forward we are able to flesh out in greater detail how those limits in terms of types of targets or in terms of duration or geographical scope and scale of use are to be determined . Are they to be linked directly with the compliance with the IHL ? Then we need to be saying that or some broader limits could also be considered . In that context , I would just like to draw attention to our working paper where we have proposed that in addition to what is required by the IHL and the application of IHL as well , we would need to establish some certain additional limits and restrictions in our Tier 2 which could support the overall objective of application of IHL . In this context , the weapon systems should restrict their targeting capacity to only objects which are military objectives by nature . A point has been raised that perhaps objects is not clearly defined or military objectives are not clearly defined . We tend to disagree . We believe that the military objectives are very clearly laid out in the IHL in additional protocol 1 , for instance , in Article 52 . However , in order to meet those , in order to implement those military objectives requirement , we need to establish certain additional restrictions and limitations in this context . Then another restriction that we have proposed in our working paper as well is that those weapon systems should be designed to only operate in situations where civilians and civilian objects are not present . This restriction has also been proposed because of the grave risks and challenges that have been often brought up by these weapon systems which are functioning in various circumstances . Now , lastly , Mr. Chair , on the question of these principles of predictability , reliability , understandability and explainability , it is often stated by a few Delegations that these principles do not have any meaning in the existing IHL or they are not used in the current rules . So perhaps it is difficult to include this in our work here . We believe that the principles of predictability , reliability , understandability and explainability are not extraneous to IHL just because they are not included in those terms . In fact , they are foundational to ensuring that these weapon systems operate within the established norms that have been set up by the IHL . So in essence , these principles are a bridge translating the abstract legal mandates of the IHL into concrete guidelines to ensure that the unique challenges that have been posed by these lethal autonomous weapon systems are addressed in that manner . For instance , if we look at predictability , if we have not talked about in the context of IHL before in context of other weapon systems , it is perhaps because the real challenges relating to predictability of these weapon systems have not been raised before the way they are being raised in the context of these autonomous weapon systems . So if the weapon system is not predictable , it is not sufficiently predictable , then its operator or its use cannot be expected to comply with the principles of , let's say , distinction at all times . Similarly , if we talk about understandability and explainability , we also believe that these principles are crucial for maintaining accountability and human oversight in the deployment of laws . For instance , these principles would ensure that human operators can comprehend and justify the actions taken by autonomous weapon systems , thereby upholding the IHL mandate of human responsibility for decisions made in the battlefield . So in that context , we are operationalizing and giving further means to apply those existing IHL principles . Then a minor observation on the bullet point which mentions the changes the mode of operation including deactivation . I think we need to be more clear here when we talk about the option , the capability of having interruptibility during all stages of operation and use by a human so that compliance with the IHL could be adhered to at all times . Thank you .",Asia-Pacific States,Yes
ITALY,11:33:44,2024-03-06,0:03:11,"Thank you , Chair . I would like to make some comments on the question concerning which elements and characteristics would make laws incompatible with IHL . Following the two - tier approach that we favor , there are two broad categories of weapons that we should consider . Laws that are fully autonomous and laws that have autonomous features that can be used either in compliance or in violation of IHL . Now bullet 1 and 2 seem to cover the first category . If a machine operates completely outside human control , then there can be no accountability under IHL . A machine cannot be held accountable under IHL . We can discuss about the different autonomous phases of operations . For instance , identifying select targets but there is little doubt that the decision to apply force must rest with the human being to ensure accountability . Now the second category , laws that are not fully autonomous must have some characteristics that make their use compatible with IHL or their use should be compliant regardless of some of their characteristics . Compliance with IHL depends very much on context to answer the other question that you posed . We cannot imagine this in abstract terms . Certainly bullet 3 , 6 and 8 are very much relevant . Being inherently indiscriminate or incapable of distinction , proportionality or precaution or being able to cause superfluous injuries or these circumstances make these weapons inherently , inherently noncompliant with IHL and must be prohibited . We do not think like others the bullet 5 qualify laws as incompatible because targeting humans directly does not in itself violate IHL . Concerning bullet 7 , we share the view of those that believe that the question of predictability is very much relevant to laws . It is very specific to laws and must be addressed in this context . We are not sure about the relevance of bullet 9 , while bullets 10 and 11 , we understand the general purpose of these , but I believe that they would need to be further clarified . I thank you , Mr. Chair .",Western European and other States,Yes
BRAZIL,11:37:09,2024-03-06,0:03:47,"Thank you very much , Mr. Chair . Regarding this set of this question that we have on the screen , I would like to make a few remarks . Firstly , I would like to concur with my Austrian colleague regarding the fact that this section , this question deals both with first - tier and second - tier elements and maybe we could reorganize the text in order to reflect this , and specifically regarding the contents , I would like to also note with appreciation the references made to the first bullet and also which was proposed by well , included in our response and also in related language proposed by other countries on the need to take into account the context and the use of laws in order to ascertain its compatibility with IHL . On this , I would like to point out that some very autonomous or at least systems that have a very high degree of autonomy are already operational for a long time in the shape of closed - in weapons systems for point defense of naval vessels . They are extremely autonomous once activated , but given their use and operational environment , they pose little if none threat to IHL . So regarding the third bullet , I would just like to make a quick point of precision . Our position papers , so to speak , the response to the questions has indicated that our preferences for the formulation of human control , I would just like to make that clear . Regarding the bullet points on life cycle assessment , I would like to note the importance that we attach to this element , especially given the evolutionary nature of lethal autonomous weapon systems that are based on machine learning . So these constant assessments of legality needs to be taken into account . I would like to draw attention to the side event that was sponsored by Australia and by Brazil earlier this week on the issue of legal review . This should be understood as a necessity not only for the initial point of development or introduction into service , but all through the life cycle of these systems . Also would like to take this occasion to point towards the Brazilian proposal to use the IEEE standard 7007 / 2021 , which is contained in our working paper number 1 . In our view , this standard , which is the first ontological standard for ethically driven robotics and automated systems offers a very good basis for a coherent , scalable and comparable approach for the design and evaluation of AI and autonomous systems . It is also an important element to be considered for the dimension of predictability , traceability and explainability , which is covered by an important proposal made by Finland on the sixth bullet . And I would also like to add my voice to the eloquent defense of these elements made by my distinguished Pakistani colleague . My Delegation will provide further details on the IEEE standard during our discussions on risk mitigation and CBMs . Finally , I would like to note the wide agreement on the importance of elements of space and time as key elements for human control from the control of lethal autonomous weapons systems in bullet 5 . Thank you very much , Mr. Chair .",Latin American and Caribbean States,Yes
ICRC,11:41:19,2024-03-06,0:05:46,"Yes . Thank you , Chair , for giving us the floor this morning . As we outlined yesterday under the previous question , certain types of autonomous weapons systems , particularly those with unpredictable effects or ones that target humans will create challenges for users' ability to comply with IHL regardless of the specific context . However , assuming that an autonomous weapon system can function in a sufficiently predictable manner and that it is designed and used only against objects , it may not need to be prohibited per se , but the way in which all autonomous weapons function creates residual compliance challenges for IHL's rules on the conduct of hostilities . In particular , we have consistently emphasized that these IHL rules call for context - specific evaluations to be made based on the circumstances prevailing at the time of the decision to launch the attack , but also during the attack . And to illustrate the definition of the term "" military objective , "" which is set out in Article 52.2 of additional protocol 1 , explicitly requires assessment of the circumstances ruling at the time . Having said that , it is standard for many of these IHL assessments to be made in advance as ex ante assessments , but when it comes to autonomous weapon systems , the difference is that the system itself triggers one or more strikes in response to environmental input . And so the human user or the commander will not know exactly when or where or against who or what those strikes will take place . So to assess the lawfulness of an attack , they need to anticipate and assess in advance the lawfulness of all possible strikes by the autonomous weapon system , and that includes accounting for all reasonably foreseeable changes in circumstances . And we consider that this exercise is only likely to be possible if stringent restrictions are imposed on the variables of the weapon system and on its operating environment environment in order to reduce the number of potential outcomes to a reasonable level . And we do see some basic aspects of these kinds of restrictions in the text on the screen . As noted by the Distinguished Representatives of the Russian Federation and Austria this morning , many of these aspects mirror this group's conclusions from last year that referred to the need to limit types of targets , the duration , geographical scope and scale of operation . We consider that these are restrictions that based on IHL already need to be imposed on the use of any weapon in warfare , and they are restrictions that are already part of military practice . For example , all weapons must already only be directed at targets that are military objectives . Now , to be effective at addressing the humanitarian legal and ethical challenges raised by autonomous weapons , this group needs to move beyond these baseline formulations to articulate the specific detail that is particular to the case of autonomous weapon systems . And I think this point was well made this morning by Pakistan . So looking at the text , for example , the references in bullets 1 and 5 to types of targets , we have recommended restricting these to military objectives by nature because the characterization of these objects is less likely to change . So there is a lower risk of an attack being directed at a protected object . Looking at the references in bullets 1 and 2 to the operational environment or the specific context , we recommend constraining these specifically to situations where civilians or civilian objects are not present in order to uphold IHL and avoid harm to these protected persons or things . On the language about scale of use , this will require further clarification , for example , specifying the number of strikes or engagements that a system can undertake in a deployment . And on the language of supervision or involvement in the third bullet point and also on deactivation in the eighth , this group will need to consider how these concepts must be implemented to uphold , for example , the ability for combatants to cancel or suspend an attack if it becomes apparent that an objective is not a military one . And the ICRC in this respect has consistently maintained that the use of an autonomous weapon cannot by itself justify a failure to take these kinds of precautionary measures that would have been available had the combatant chosen another reasonably available means or method of attack . So the ICRC urges high contracting parties to take this opportunity to now move to providing this kind of detail to address the particularities of autonomous weapons and to respond to the need for progressive development of the law as recognized in the CCW preamble and as highlighted this morning by Delegations including from Austria and Peru . Finally , Chair , looking at the use of the term operator and this point applies equally looking back at the first topic , we would recommend the kind of broadening that was raised this morning by the Distinguished Representative of Austria . Our recommendation previously has been to use the term users or alternatively to specify that IHL obligations bear not only on operators but on all commanders and others responsible for planning , deciding upon or executing attack . We think this would better reflect IHL obligations including that precautions in attack need to be taken by those who plan and decide upon an attack . Thank you , Chair .",Non-applicable,No
LUXEMBOURG,11:47:20,2024-03-06,0:03:56,"Thank you , Chair . We also would like to react to different points that were raised and express our national position . Luxembourg believes that we must have an inclusive definition and clear regulations that will make it possible to have a framework for the use of such weapon systems with the necessary precautions related to meaningful human control and decision making process and relevant legal reviews . Now , the advantages that are offered by laws , the objective is not to prevent the functioning of such weapon systems but ensure that we establish an approach that is based on human beings to avoid any unintended consequences of their operations . But human control is not limited to monitoring systems and decision making . After the development phase , it is necessary to put into place relevant legal reviews to ensure the reliability and predictability of such systems . Once activated , the systems must act in a predictable manner in line with IHL reflecting the intentions of the commander and operator that requires the sufficient understanding of how the system functions . In this context , we are in favor of a future oriented approach because responsibility falls on the shoulders of operators . This means that operators have to be able to anticipate the different ways the system can function in order to avoid any operations that do not comply with IHL . They also have to understand the actions that were taken by the system . This reflects the fact that the legality of the use of autonomous system is directly linked to the circumstances of deployment and something that was already mentioned by France , Switzerland and other Delegations during the deployment phase . Legal autonomous systems identify the mission and type of targets and also establish geographical and temporal limits on their operation establishing a specific framework operators can prevent the very complex situations that may lead to violations of IHL . Also human judgment related to respect of the rules of IHL , for example , distinction and proportionality is crucial in the context of the ethical decisions related to the use of force . The implications of the use of systems that have been sufficiently tested can guarantee that these systems will be operating with full respect of IHL and operators should be familiar with all environmental factors and technical modalities of these systems to the extent possible in order to ensure that the use of such systems does not violate the principles of proportionality . Finally we attach great importance to human approval of any substantive modifications of the parameters of the mission in this respect the system cannot take a decision in autonomous manner related to the parameters and objectives of the missions neither the geographical or temporal framework of the mission in order to ensure conformity with IHL the capacity to deactivate the system when and if it is necessary should also be foreseen . In this context we also would like to once again draw attention to the nonpaper of Germany and France that Luxembourg co-sponsored related to the setting of the necessary regulations based on a two - tiered approach . Thank you .",Western European and other States,Yes
CANADA,11:51:34,2024-03-06,0:04:06,"I would like now to pass the floor to the Distinguished Representative of Canada . Sir , you have the floor . Thank you , Chair . My Delegation would like to make a few comments related to the compatibility of autonomous weapons systems with IHL . First , we believe that it is important to stress the distinction between weapons and prohibited attacks . Now , if I refer to your first question , points 8 and 9 , in the framework of IHL it is prohibited to use a weapon that will be first then lead to superfluous harm and be of discriminant effects and also may lead to widespread damage . And these two restrictions are reflected in AP1 to the Geneva Conventions . Also under the first questions , in addition to the two prohibitions that I referred to , a weapon system can be prohibited in line with IHL in light of specific customary law or the provisions of a specific convention . Now , if a law system does not respect these prohibitions where it is used , the system will be intrinsically incompatible with IHL . Nevertheless , it will be difficult to attribute the general qualification to the autonomous weapon system where the application of IHL depends on the operational context to which the system was in which the system was designed to operate and this leads me to the second question , the relevant rules related to warfare that are prohibited are crucial in our analysis . Chairman , any weapon system can be used to carry out an attack that will be in violation of the rules of IHL related to distinction , precaution or proportionality . The operational context in which the weapon system is used is very important in order to determine the legality of its use . Even a system does not have its own capacities to distinguish objects from persons on the basis of relevant criteria of IHL can nevertheless be legally used in an attack with the condition that the operator has already determined that within the geographical area where the weapon will be used , there are only legitimate targets . Autonomous weapon systems can depend strongly on parameters that was programmed with sensors . These weapon systems can limit , anticipate and control , but it is necessary for these parameters to be very strict and rigorous . For example , what was mentioned by the Distinguished Representative of Brazil's automated system that can combat incoming missiles or drones are capable to function according to rules of engagement that have been defined with an acceptable level of reliability in line with IHL . As a result , my Delegation believes that we have to be careful in suggesting that autonomous weapon system will be fully incompatible with IHL on the basis of only of its characteristics . If the use of a weapon system in attack leads to the violation of rules of IHL related to methods of warfare , then the use of such a weapon system will be incompatible with IHL , but it does not mean that the weapon itself violates IHL . Thank you .",Western European and other States,Yes
UNITED STATES,11:55:53,2024-03-06,0:09:52,"Thank you , Chair . And thanks also to our colleagues this morning for continuing the very substantive discussion from yesterday on the application of IHL . Similar to our approach to the previous question , we plan to provide some overarching reactions to this question now at the outset of the discussion and then in later interventions we will provide more detailed comments on the bulleted responses and try to react to other Delegations' comments as well to continue what we view as a very good interactive discussion . As we noted yesterday and as affirmed by a number of other Delegations this morning , we understand the Chair's first IHL question and topic 2 to be addressing the first tier of the two - tier approach and the second question to be addressing the second tier . Although many Delegations support the two - tier approach as a way to frame our thinking about the application of IHL , it seems to us that colleagues may still have different understandings of what these tiers are . For the US Delegation , we understand the two - tier approach to reflect a basic distinction found in existing IHL between weapons that are by their nature prohibited from use in any circumstances on the one hand and on the other hand , the rules governing the use of other weapon systems that are not per se unlawful by their nature . One way that our draft Articles try to operationalize this concept is to think about Tier 1 in the design and development phase so that states are not developing weapons that are per se unlawful . Then with respect to Tier 2 , we think about how weapons are used to conduct attacks . For the US Delegation , there are prohibitions and regulations in both tiers . For example , as we conceive of Tier 1 , we can have prohibitions against deliberately designing weapons that are inherently indiscriminate or otherwise in contravention of IHL requirements . But we can also have regulatory measures such as legal reviews or potential weapons during development that help ensure that weapons are not per se unlawful . Similarly , as we think about Tier 2 , we have both regulations and prohibitions on the use of weapon systems . For example , it is prohibited to use any weapon to target civilians for attacks . That is a legal prohibition . We also have regulatory measures or restrictions such as taking feasible precautions in the planning and conducting of attacks to reduce the risk of harm to civilians . So we consider the control of the weapon or how the operator uses the weapon as what takes place during Tier 2 . How you control the weapon is related to how you use it rather than about the weapon's intrinsic characteristics . We think it is important to explain this point because we want to make sure that we are developing common understandings . It is also important for us to note as we did during our discussion of definition characteristics and as I think the Delegation from Canada just noted that we remain concerned with labeling the two tiers as related to fully autonomous on the one hand and partially autonomous as the other as we believe there are already examples of fully autonomous weapon systems that are clearly not per se unlawful . So turning back to this question , we interpret the Chair's second question as relating to IHL rules on the use of laws . It was surprising to us that under the overarching topic of the application of IHL that none of the proposed responses to the second question refer to IHL rules on the use of weapon systems . With the exception of the last bullet in this section which does reflect a rule of IHL , not a primary rule of IHL but a rule of IHL on the use of weapons , all of the bullets that we have before us describe possible measures that may enable compliance with IHL . So for our Delegation , these bullets do not fully address the legality of the use of laws because none of the bullets reflect existing rules that govern the use of weapons . In order to identify whether the bullets in the section are relevant , our Delegation suggests that we first articulate the existing rules of IHL and then specify how possible measures reflected in these bullets relate to those existing rules . I want to be clear , we are not seeking to simply engage in an exercise of identifying existing law and then end the conversation . Rather , we are looking for a starting point that provides a common foundation for our discussions . From there we can determine how existing law applies and as suggested by the ICRC yesterday , explore what measures may be useful to apply those existing law to apply existing law to the specific laws context . We think it is critical that we are methodical and legally rigorous about drawing conclusions about the legality of using weapons under IHL by being specific about what existing IHL requires , how it relates to emerging technologies in the area of laws and how possible implementation measures may enable compliance with those IHL requirements . In line with our comments on the first question , we think we should use existing agreed language as a starting point and build from there . We have previously agreed conclusions about the legal rules governing the use of laws in attacks from the 2019 GGE report . For example , Paragraph 17 F stated compliance with the IHL requirements and principles including inter alia distinction , proportionality and precautions in attack in the potential use of weapons systems based on emerging technologies in the area of lethal autonomous weapons systems requires inter alia that human beings make certain judgments in good faith based on their assessment of the information available to them at the time . There are also several paragraphs of agreed language in the 2019 report and other reports that we could build on . Once we have identified these existing legal requirements on the use of laws , we can then identify concepts and / or measures that enable compliance with those IHL requirements and assess how those concepts are tied to specific rules . We have previously agreed language on this as well that we can further build on in our discussions this year . Although we will provide a more specific intervention that gives feedback on each bullet , I just wanted to provide one example to illustrate or one or two examples to illustrate how we recommend proceeding . Take bullet 5 regarding imposing limits regarding space and time of the operation of the weapon system . We do not think this is a rule of IHL . However , that does not make the bullet irrelevant or unimportant . We have similar language in the draft Article's proposal that we and several other Delegations developed that reads adjusting the location where or times when the system is operating to reduce the likelihood of civilians being present . That is just an example of such a measure that could be included in these bullets . However , in our draft Article's proposal , we do not posit this is a rule of IHL but as a potential feasible precaution . Taking feasible precautions in planning and conducting attacks to reduce the risk of harms to civilian is a rule of customary international humanitarian law . Adjusting the timing or location of a system's operation could depending on the circumstances be a feasible precaution that is legally required . I think our colleague from Switzerland in his intervention earlier did a very good job of explaining this concept , the importance of context . Similarly , we were able to achieve consensus just last year on a similar formulation in Paragraph 22 of the GGE's 2023 report to the meeting of high contracting parties . There we recognized that states should take a series of steps when necessary to ensure compliance with their IHL obligations including placing certain limitations on duration and certain limitations on geographical scope . We supported these measures as very useful and as noted by Japan this morning , this is the type of language , language we have already agreed on that should that we should further discuss in order to deepen our understanding of these measures . What is critical to us here is that we have linked the measures to a specific rule of IHL . We have also provided guidance about why we are adjusting the location on the timing of systems operation to reduce the likelihood of civilians being present . For our Delegation applying a methodical and legally rigorous approach is important for providing clear guidance to states on why states need to take certain measures . Thank you , Mr. Chair .",Western European and other States,Yes
INDIA,12:06:07,2024-03-06,0:01:08,"Thank you again for the guiding question and the points that you put out on the screen . These are extremely useful . As we see it , the points that you have brought out can be viewed from several perspectives . One perspective is according to whether these are existing law or derivatives of existing law or whether these fall in the category of new law . The second is in the perspective of the two - tiered approach and the regulations that may constitute what could be a possible second tier . We have carefully heard the views that have been expressed by Delegations . As I have said before , our Delegation's approach will be guided by the nature of obligations and commitments . My Delegation has an additional consideration . It is a preference for measures that are framed in a manner that correspond to current military reality . In other words , the consideration should be framed in a manner that is capable of actually influencing the use of laws in a battlefield . Thank you , Mr. President .",Asia-Pacific States,Yes
IRELAND,12:07:29,2024-03-06,0:03:39,"Thank you , Chair . With regards to the topic of human control , we would wish to highlight a number of fundamental points that we believe should form the basis of our discussions . We believe these points are longstanding and agreed aspects by the GGE . Further and perhaps more importantly , we must remind ourselves that these discussions on human control are not merely abstract or theoretical . They are , in fact , tangible and corporeal and they can and do have real world human implications . Chair , for Ireland , the necessity of retaining human control over the weapon systems is critical . This cannot be understated . There can be no accountability gap in the design and development of autonomous weapon systems . Further , we firmly believe that the decisions to deploy and use autonomous weapon systems must be retained within a responsible chain of human control and command . This includes exploring constraints on the targets and the tasks of autonomous weapon systems , imposing temporal and spatial limits on the operation of autonomous weapon systems , maintaining the ability of human supervision or integrating fail - safe mechanisms . Chair , human responsibility and accountability cannot under any circumstances be transferred to machines and must be maintained throughout the entire life cycle of all autonomous weapon systems . Only states and individuals are responsible and accountable for applying the law and they are the ones that must be held accountable for any violation . Additionally , Chair , on the human control involvement supervision point , which I think is bullet point number 3 , we would wish to emphasize the value of human judgment within the conduct of hostilities which calls for context specific evaluations to be made . The reasons why context and circumstances can change within the conduct of hostilities are multiple and varied . These contexts all require human judgment . A machine simply cannot make these value judgments or at least not at the level of comprehension that a human can . For example , detecting or interpreting unintended behavior cannot be identified by a machine . This is what is meant by meaningful human control , a type of control that is involved in every level of decision making necessary . In our view , Chair , it is indeed quite limiting to say that compliance with IHL depends on the specific autonomous weapon system being designed or developed . As highlighted in our intervention yesterday , it is from the design stage of an autonomous weapon systems that it is clear that a system cannot comply with IHL . This includes any systems that incorporates self - learning or machine learning or in situ learning and other types of AI . Unless an autonomous weapon system actions can be fully predicted or understood , by definition , it cannot comply with IHL . In this context , having a legal or weapons review after an autonomous weapon system has already been developed leaves a glaring gap in our understanding . The fundamental point here is that these systems have not addressed these issues of explainability , predictability and understandability regardless of how we choose to interpret them . The continuously self - evolving nature of these systems raises significant legal and ethical challenges and we have not been able to address these gaps . Chair , we believe we should not be rehashing old definitional debates but instead focus our attention towards finding the common ground , building on a two - tier approach . It should be a given that if you cannot fully explain , predict and understand how an autonomous weapon system functions , this system cannot comply with IHL and should therefore never be designed , developed or used . I thank you , Chair .",Western European and other States,Yes
AUSTRIA,12:11:22,2024-03-06,0:04:55,"I have five points that I also wanted to make in light of the discussions but also to add a little bit to what I have presented before . The first point is maybe what has been already indicated by the United States on this whole section that we are having here in front of us that the chapeau as it is right now maybe could create some confusion or problems while in an abstract way we , of course , agree that many of these or most of these elements are related to the legality of laws . In a further phase we need to be more specific in what way . Otherwise we are creating confusion and problems and it is very important that we get this right in any future document and not to simplify it . So while we are seeing that the way of discussing is very useful and fruitful , a simplified chapeau also leads to certain problems and misunderstandings . The second point what has also been raised by the United States is the issue of the tiers . Here I would also plea for having this discussion maybe in the next phase . It is an important discussion . But at the moment I think it would be rather a hindrance . In the end we should have elements on the table that we then sort into two tiers . There is also apparently this important discussion about is the tier are the two tiers the tiers of prohibitions or regulations or are the two tiers those of two different types of ways to deal with IHL . It is an important discussion to have but probably in the next phase . Third point , what we have not introduced yet but which is an important part of our working paper and which is missing on this list is the functional understanding of the system . We see this as a different element than what has been introduced as context or informed decision . In our view functional understanding and here I quote the working paper means that those authorizing any use of weapon systems that integrates autonomy in its critical functions of selecting and applying force to a target must have an adequate understanding of the system under consideration . They must understand what circumstances or conditions will trigger the system to apply force including conditions that would trigger an unintended engagement . Moreover it must be possible to trace back the outcome of the use of force to human agency . So as explained before this is a different element than the other ones that we are seeing on the screen . It is still also important and as I have said we also think that context and making informed decisions but also here we have a slightly different phrase but it is the same idea are important . So it is in the end three elements . Fourth point I also wanted to support the point as Brazil did , the point that was made by Pakistan , that the concepts that we have strongly discussed last year of predictability , explainability , traceability are kind of a bridge , a bridge that links IHL to this novel technologies to this new type of weapons or also new methods of warfare . And they it is no accident that those kind of concepts are not completely new to the world of AI . They are part of the UNESCO ethical principles which have been agreed by all states in the UN system . So basically practically everyone in this room . And they are also used in several policy documents not only in the civilian field but also in the military domain . So those are not completely novel concepts . We understand the argument that they are not part of IHL but as I have said Pakistan has made a very good point . They serve as a bridge between those new technologies and the existing IHL . And maybe a last point that more relates to our discussion to the previous question , we had some discussion on bullet 5 in the other question . Here also we want to refer to our working paper which in para 15 and the second bullet offers more of a procedural approach to this that on the one hand links the ethical elements to the ways those weapons are used but also has a link to IHL through formulations that people might identify as the Martin's clause and this while we know that it is widely disputed we want to have this discussion also as part of our way forward . I thank you .",Western European and other States,Yes
BULGARIA,12:16:39,2024-03-06,0:02:26,"Thank you , Mr. Chairman . In our view the lawfulness of autonomous weapons systems could be considered in relation to the operational context they operate in and the nature type of their targets . Nowadays the majority of the armed conflicts are fought in urban areas in the consistent presence of civilians and civilian objects . Deployment and use of autonomous weapons in such context complex urban environment poses additional challenges and increases significantly the potential of breaches of IHL norms and its principles more specifically distinction proportionality and precaution in attack . Such a situation would demand the introduction of further regulations including by implementing certain policies and risk mitigation measures . On this we will share our thoughts in the next phase of our phase on the guiding questions . We consider human control to be central to IHL compliance and ethical acceptability of autonomous weapons systems . The extent and type of human control depends on the complexity of the operational environment on the intricate characteristics of the weapon systems themselves and their capabilities and capacities and also on the intended use and assignment tasks to be performed . To ensure employment of such weapons systems fully complies with IHL and its key principles human control must be preserved and retained at the various phases of research development , validation deployment and use of autonomous weapons systems . But for us primarily in the targeting cycle as ICRC pointed out yesterday IHL does not technically demand existing human control in all stages but requires control of the effects use of force of weapon systems . Also more specific on bullet 5 we appreciate the inclusion of limitations as it in a way reflects the 22 of the last year report which in our view certainly requires further elaboration .",Eastern European States,Yes
REPUBLIC OF KOREA,12:19:18,2024-03-06,0:03:47,"Thank you , Mr. Chair . My Delegation finds the current ongoing discussions very helpful . It is indeed very serious interaction of centering around concrete agenda topics and this over the last days we find that this is very helpful in understanding the overall sketch of where Delegations are and where we are going with the items . On specific bullet points we really have nothing to add to the very eloquent comment made by the Distinguished Delegate of Australia including all the commas and periods we would like to copy paste . We will not repeat it . But I do have a confession to make . The current the breadth and the number of the subtopics we are dealing with currently and the length of each Delegation's remarks are beyond my human Delegation's cognitive ability to fathom . So we would actually support what the United States and Sweden and I think Austria also said to structure our work in a bit more I guess dissected ways . The current questions laid out we also take it as questions for Tier 1 and Tier 2 . It does have its meaning but there are too many factors included in each subtopic . So we would actually propose to actually divide and understand and seek agreement , taking a phased approach . For instance , since we are talking about IHL as the United States Delegate suggested we would like to discuss in more detail how the three principles of distinction , proportionality and precaution would apply when we talk about prohibitions and regulations . For instance , in light of the particularities of laws as ICRC put it , for instance , when we talk about the prohibition of laws and we would suggest to specify how the concept of distinction would apply . In essence , as others in the joint proposals states , we saw that laws designed to target and attack civilians would be already prohibited by the IHL . So we would like to actually spell out those specific requirements elements that would make either laws either prohibited or something to be regulated . My Delegation also is ready to discuss elements that would go beyond the IHL elements but we would actually propose to start by focusing on the IHL first so that we can move on within our cognitive abilities . And also we would like to add that rather than repeating our vested national positions or interests , we build our discussion around previously agreed or nearly agreed previous elements and that would also help to actually move together on the subtopics . And if you look at the annex of the joint proposal , those elements under subheadings are also organized . I hope that would be helpful to other Delegations as well . Thank you .",Asia-Pacific States,Yes
UNITED KINGDOM,12:23:24,2024-03-06,0:08:04,"Thank you , Mr. Chair . Mr. Chair , in brief , the answer to the question does compliance with IHL depend on the use of laws in a specific context , the answer is yes . As we have said before , international humanitarian law is principle based and it looks at how a weapon is used and its effect and it applies to all weapon systems autonomous or not . Turning to the specific bullets , if we were to take the chapeau literally , then the answer is that the legality of laws depends on the circumstances of their use and their ability to comply with IHL . Similar to our intervention yesterday on the compatibility with IHL question , there is a risk that we potentially confuse inherent incompatibility with IHL and incompatibility that might have an element of use . The chapeau could usefully be used to provide a clear statement of the importance of the accountability of the state actor in servicing the requirements of IHL in the context of the particular action . The question is not about the intrinsic lawfulness of the weapon , it is about the lawfulness of the manner of use of the weapon , taking into account the nature of the relevant capability and the legal considerations applied by the commander in the prosecution of their objective . The first three bullets are actually a setting of those contextual factors rather than a matter that regulates the lawfulness of the use of the AWS . As with any weapon operators would need to take into account the nature , manner of functioning of the weapon , the use or objective of use of that is being put to and the environment in which they are operating . Equally the third bullet which speaks to the nature of human machine interaction is a critical issue in relation to how the autonomous weapon system will be used in a lawful manner , rather a factor of lawfulness in itself . All of this speaks to context , so the first three of the bullets here need to be reframed in that regard . In relation to the third and fourth bullets where we see reference to life cycle in two of the options , the UK position is that context appropriate human involvement engages human involvement in a manner and at a point that is necessary to ensure the use of the autonomous weapon system complies with IHL . The life cycle is important to ensure that the commander can affect the necessary controls and constraints whether they be to the environment of use or the operation of the system itself . This is not just technological in nature . It cuts across technology development and testing , training and operationalization of systems , development of operating procedures , training of personnel involved in the use of laws , decisions made regarding where and when to use your laws and mechanisms for reporting and feeding back concerns regarding the use of those systems . Therefore , the UK would suggest bullet 3 and 4 could read context appropriate human involvement across the life cycle of the AWS is necessary to ensure that the use of AWS is in compliance with IHL . Bullet 5 is the critical bullet in relation to the types of considerations and constraints that might depending on context support the subjective , the objective of compliance with IHL . The UK would suggest further clarity is needed in focus of this further clarity is needed in focus of this bullet such as who or what are we referring to when we refer to the operator . Is this the state using the autonomous system or the person who is operating the system sitting at the controls ? Or everyone across the chain of command involving decisions to deploy and use the laws . We note and agree with the ICRC's comments in this regard to clarify and broaden the application of the term operators . In relation to limitations on space and time of targets , duration of operation , geographic scope and scale of use , geographic and temporal constraints are indeed sensible . Limitation on target types are obvious but the risk of misidentification of entity or target type in terms of complex targets would need to be taken into account . The UK would expect the human operator to be able to limit and vary the behavior of the laws depending on the context of use . This might include geographic and temporal constraints , permissible behaviors and levels of autonomy . The bullet on predict , trace and explain the behavior of the laws is one upon which we had a fairly long debate in the final session last year . If we are still addressing the question of lawfulness of use , we need to address how each of these criteria relate to that lawfulness concept which is perhaps a matter for further discussion and extrapolation . The ability to predict effect is , of course , a matter that is inherent in the decision in relation to the manner of attacking the principles within the principles of IHL . It would underpin questions around distinction , proportionality and arguably humanity . Prediction of exact behavior is less clear in terms of the relation to IHL . How accurately does the operator need to be able to predict the behavior of the system ? By its nature , exact behavior may be unpredictable or only predictable within bounds . An unpredictability of maneuver in response to offensive maneuvers of an opponent or in order to change route might be a desirable characteristic in certain capabilities . In relation to explaining the behavior of laws , the concept of explainability and the concept of artificial intelligence is a complex subject and we need to be clear about what we mean here . We would need to clearly understand what we mean by explainability and how it relates to the predictability of effect before tying the concept to lawfulness of use of a capability . Traceability is also related to the secondary obligations attached sorry . Traceability is also related to the secondary obligations attached to the accountability of states and persons for the conduct of hostilities . This concept would be better articulated in that context . In relation to point 7 and the requirement to make informed decisions about the deployment and use of weapons and have sufficient information to ensure that well , to ensure that , while we do not disagree with the requirement that the deployment and use of autonomous weapons systems must be supported by sufficient information to ensure that the use of force is in accordance with IHL , it is not clear whether this bullet is again not clear whether it is aimed directly at the operator or others within the chain of command . So we would suggest those in the chain of command responsible for decisions regarding the deployment and use of laws are appropriately trained and have sufficient information regarding the capabilities and limitations of the laws in the environment and context within which it is used to ensure that it can be used in accordance with IHL . With regards to deactivation , we would note that while deactivation may be a credible constraint in some situations , it may not be a suitable feature for some system types or applications . It is part of the variety of features that might be suitable depending on context , including the mode of operation of the system itself , whether it is fully or semi-autonomous and where it is operating . The UK believes that this text has been useful in relation to the discussion around the sorts of constraints that might apply in relation to the regulation of systems to ensure the compliance of IHL . We would reiterate comments made at the start of this intervention that we need to be very clear that the context of use is a critical factor in relation to the lawfulness of the manner of use which speaks essentially to the second tier of the two - tier structure . It is important that we do not conflate lawfulness of use with intrinsic lawfulness of the weapon , particularly if this engages IHL requirements at different phases of the life cycle of the weapon . The UK would again point to the joint proposal draft articles for a useful structure in relation to the tiers and regulatory measures . Thank you .",Western European and other States,Yes
VENEZUELA (BOLIVARIAN REPUBLIC OF),12:31:49,2024-03-06,0:04:27,"Thank you . As it is the first time we have taken the floor , we would like to thank you for the preparation of the questions , indeed complying with the ideal of stimulating our discussions on this topic . We would also like to thank you for the compilation of language that you have used to identify the possible responses to the questions that have been posed . We think that for the Delegations of the parties , especially small Delegations such as my own , it would have been good to have access to this language and key concepts much earlier , allowing us to look over them . My Delegation can nevertheless make some general comments with regard to IHL in the light of the discussions taking place in this meeting . My Delegation does not support this approach or the implications according to which the laws may be compatible or beneficial for the implementation of IHL according to specific concepts . For us , the incompatibility of laws with IHL is not a hypothetical or potential situation and within the discussions of the group , the Delegation has argued that the laws impose a retroactive implementation of IHL . First of all , there is a lack of distinction in IHL requiring that parties to conflict and as well as military and civilian objectives cannot be designed to take into account this distinction in a reliable way and therefore incompatible with IHL laws as well as being programmed to try to take into account the distinction between these targets and may lead to indiscriminate application because of limits in design and therefore are incompatible with IHL . Secondly , the inability to comply with proportionality , they may cause incidental damage to civilians or civilian objects that are excessive in relationship to the military objective . This cannot be undertaken effectively and so are therefore , laws are , therefore , incompatible . Like a precaution , IHL requires that precautions are taken in order to minimize harm to civilian populations . If they operate without human control , laws cannot comply with this requirement as they cannot adapt to changes in operational contexts or to evaluate the risk of collateral damage in adequate way . Fourth , lack of meaningful human control to ensure that the use of force in armed conflict is incompatible with IHL and the capacity to intervene also contravenes its principle . We know that the context requires a retroactive implementation of IHL in context of laws . However , the capacity of existing international law including IHL to address all legal shortcomings particularly with regard to human control or meaningful human control independently from the context in all stages including design and programming is one of the reasons why my Delegation has requested a negotiating mandate within a legally binding instrument for this aspect . In any context , the design and programming and development and deployment of these weapons requires keeping human control because a machine cannot make the necessary value judgments or detect or interpret a nonintentional behavior , for example , in changing contexts as would be able to a human controller or operator . For any autonomous weapon systems which complies with IHL , the results should be undertaken . But the systems , for example , introduce elements of unpredictability which means that it is difficult to ensure compliance in all contexts . Thank you .",Latin American and Caribbean States,Yes
BRAZIL,12:46:58,2024-03-06,0:00:45,"First time we are looking at the text and we again thank you for preparing this compilation . I would just like to point out that in our national response we have proposed as a possible CBM the adoption of the standard that I already mentioned earlier today in our intervention , the IEEE standard 7007/2021 for ethically driven robotics and artificial intelligence . I think this is something that should perhaps be reflected in the text as well .",Latin American and Caribbean States,Yes
