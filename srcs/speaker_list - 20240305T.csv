Speaker,Time,Date,Duration,Statement,Region,High Contracting Party
FINLAND,15:22:51,2024-03-05,0:04:04,"Thank you very much , Mr. Chairman . Thank you , Mr. Chair . We thank you for providing a comprehensive set of questions that guide our discussions this week . We find your practical approach by engaging us in discussion based on text proposals to be highly useful . Sufficient human involvement throughout the whole life cycle of a weapons system is at the core of the legal design and deployment of weapons system incorporating autonomous features or functions . Laws operating completely outside of human control and responsible chain of command are incompatible with international law , including international humanitarian law . Autonomy is always a relative concept . Our baseline is that autonomous weapons systems operating without sufficient human involvement should not be developed or used . But a sufficient level of human involvement should be at the core of our discussions . Furthermore , laws must be developed and deployed in a manner that ensures compliance with the customary IHL principles of distinction and proportionality . Properly executed legal reviews in accordance with Article 36 of the first additional protocol across the life cycle of laws play an important role in ensuring their full compliance with IHL . Let me note that sufficient human involvement across the entire life cycle of weapons system does not require the technical ability to cancel an already commended attack . In addition , having a continuous connection to the weapons system is not required if taken into account while development of the system as well as missions operational planning . When assessing the compliance of laws with IHL , contextual assessment is crucial . Using the even laws that are not inherently incompatible with IHL can be used in violation of IHL . The final decision on the deployment of any weapons system requires an understanding of the complexity of the task and high human ethical standards to aid military necessity as well as risks related to the operation . To determine the legality of the operation , several criteria need to be taken into account . Among others , a specific and limited mission framework and the operational environment as well as the foreseeability of the operation . These criteria and limitations form a complex set of parameters . The responsibility and accountability for these assessments and decisions must remain with humans . Finally , the characteristics of the elements of the regulatory instrument should be future proof . On the one hand , more precise and clarifying principles below the level of abstraction of IHL and on the other hand , principles above the technology specific practice are sought after . Principles that can be implemented in reality and practice in code and hardware . In the early years of the law's process , we were all exhausted by the expert briefings . However , in recent years , the speed of development in AI domain has rapidly accelerated exceeding the expectations . To be able to reach the required level of abstraction , we suggest for future GG law sessions that carefully selected technological briefings highlighting the advanced present as well as foresight the future development of AI would be heard . Especially the understanding on the consequences of AI for the cognitive capabilities of autonomous weapons systems would marry the quality and technological realism of our challenging task process . Still , humans must draw the red lines in the tasking phase and those remain contextual by nature . Thank you , Chair .",Western European and other States,Yes
IRELAND,15:27:09,2024-03-05,0:03:09,"These fruitful and substantive discussions and the format you have chosen , we believe this is the way forward towards increasing convergence on the topic . Chair , autonomous weapons systems pose various challenges with regard to IHL . In particular , this includes factors such as unpredictability , the complex context based decisions necessary in the application of force , the need for qualitative human judgment and algorithmic biases . We need only point to the abundance of scientific , academic and civil society research contributions in these areas which underline time and again the value of human centrality . The pressing need to address the issue of explainability in AI and addressing bias and ethical considerations more broadly . A specific question of which elements , characteristics or characteristics would make autonomous weapons systems incompatible with IHL , we would point more broadly that this should refer to autonomous weapons systems that cannot distinguish between military and civilian targets . This is particularly relevant to autonomous weapons systems which rely on artificial intelligence techniques , on machine learning and which prevent the human user from being able to understand , predict or explain the system's output . This impossibility effectively results in a lack of control over the weapons effects , making it potentially indiscriminate by nature . We refer here to what is commonly called the black box challenge and which refers to the design of autonomous weapons systems that arrive at conclusions or decisions without providing any explanation as to how they were reached . Additionally , and as our colleagues in the ICRC have highlighted , in such systems , target selection is based on a generalized target profile that is unlikely to be able to account for the non-exhaustive range of contextual signals showing that a person is protected from attack . Whilst the user or commander may have made a general assessment that one or more people in the area constitutes a lawful target at the time of launching the autonomous weapons system , those people's actions , intentions and physical state and hence their qualification as a lawful target can change rapidly . The IHL rule on distinction requires assessment on the concrete circumstances prevailing at the relevant time and place . By definition , Chair , these types of systems cannot comply with IHL as their function cannot employ the IHL principles of distinction and proportionality . Chair , we believe that it is important that we have convergence in the room on this fundamental point . Systems that are fully autonomous by design or that do not include meaningful human control cannot comply with IHL . My Delegation remains flexible on how effective regulation is achieved , including through a combination of positive and negative obligations , legal and practical measures that ensure compliance with IHL . But the important point here is to ensure compliance . If there is doubt about a system , then it should not be used , developed or designed . I will leave it there now , Chair , but thank you .",Western European and other States,Yes
UNITED STATES,15:30:31,2024-03-05,0:04:55,"Thank you , Mr. Chair , for including this topic for discussion this week . For now , we just wanted to offer a few overarching comments rather than go bullet by bullet and we will return to the bullets later in the session . For our Delegation , working to develop elements that advance the group's shared understanding of the application of IHL is critically important . At the outset before we get in to some more detail , we wanted to actually start by commenting on the framing of the question as we found the reference to elements / characteristics that would make a laws incompatible with IHL to potentially be susceptible to multiple different interpretations . This could complicate our discussions as IHL requirements apply to laws and to the use of laws and not necessarily to specific elements or characteristics of laws . We thought the word "" elements "" could also be misunderstood as intending for this list to articulate criteria that all must be met before the weapon is deemed incompatible with IHL which as you just noted in your opening is not necessarily the intent . What we would propose instead is to reframe the question to focus on weapon systems rather than on elements or characteristics that are , quote , incapable of being used in accordance with IHL . This would help clarify the notion of what is meant by incompatible with IHL and its previously agreed language . This framing would then allow us to focus our discussion around the two tiers beginning with Tier 1 which is weapons that are prohibited from use in all circumstances . We could then move on to the second Tier which is restrictions on use applicable to other types of weapons under the second question you posed in the IHL section . Chair , we also wanted to offer a recommendation for how to organize our discussion in order to progress our work both this week and in future sessions . The GGE has a significant body of consensus language that covers many of the concepts included in the various bulleted responses to this question . We would recommend starting from that language and then working together to try to build upon that language by drawing on the responses to your guiding questions , interventions from the floor and the prior proposals submitted to the group . So for this question , for example , we could start with the sixth revcon language that a weapon system based on emerging technologies in the area of laws , quote , must not be used if it is of a nature to cause injury or unnecessary suffering if it is inherently indiscriminate or if it is otherwise incapable of being used in accordance with IHL . This is prior consensus language and it incorporates many of the bullets on this page . It could then be expanded upon during the coming days or sessions . Finally , under both the first and the second tiers , it is really important for our Delegation to distinguish between prohibitions and regulations that are requirements under IHL and measures or good practices that may enable compliance or effective implementation of IHL but are not themselves requirements . So I just wanted to give a few examples to highlight what I mean by that . Related to the first bullet , as we have explained before , our Delegation does not believe there is an existing IHL requirement of meaningful human control . As another example related to the sixth bullet on this list , weapon systems that are incapable of being used in accordance with the principles of distinction and proportionality are prohibited . These are cardinal IHL requirements . However , the bullet that follows that starts with effects cannot , and then refers to concepts like predictability and reliability are not themselves IHL requirements . And to be clear , that does not mean that we should not talk about these terms or explore them further . We just need to be precise about how reliability relates to IHL requirements . In our draft article's proposal , we seek to do just that and have proposed language on how reliability relates to the principle of distinction . As a final example , with respect to the fifth bullet which says , quote , are designed to target humans directly , end quote , there is no prohibition under IHL on designing laws or any weapon for that matter to target humans directly . In our draft article's proposal , we seek to reflect IHL by prohibiting efforts to design laws that target civilians . So for now , again , as I said , we just wanted to share these overarching reactions to the framing of the question , and we will go through specific points in a later intervention . Thank you .",Western European and other States,Yes
RUSSIAN FEDERATION,15:36:16,2024-03-05,0:16:41,"Thank you very much , Distinguished Chair . We also would like to share with you some of our ideas related to the application of IHL to these weapon systems . First of all , on the question that we have here at as the chapeau , we believe this question is , once again , somewhat not fully correct if we are referring to this particular group of weapon systems . The very presentation of the question about which elements or characteristics of these weapon systems make them incompatible or place them outside of the framework of IHL creates a feeling that we are presenting this category of weapon systems as a separate type of weapon systems in the context of the application of IHL , as if this type of weapon systems is something special in terms of the characteristics of the characteristics of these weapons in the context of the application of existing IHL . But that is not the case . This is something that is confirmed by the understandings and the conclusions that were adopted by the group in previous years . Now , if we ask ourselves a very simple question , in which cases does a lethal autonomous weapon system violate international human rights and humanitarian law , the answer will represent a list of cases when such weapon systems will not be compatible with existing norms and principles of existing IHL . And this is exactly the understanding that has been enshrined in different forms in the previous conclusions of the work of the GGE report . This is something that was done in the 2019 report . I am referring to Paragraph 17H or 17G . This is something that we also will find in the guiding principles . These understandings were reflected by the group in the report that we adopted last year . And I would like to thank Ambassador D' Amico , Distinguished Ambassador D' Amico who chaired the work of that group . And I have in mind Paragraph 21 of the report and the subparagraphs that we find in that paragraph . They have a direct bearing on the question of the application of IHL to these weapon systems . Moreover , if we carefully look at the bullet points that we see in this list , they are in one way or another , they represent in one way or another a narrow interpretation of already existing principles of IHL . This is why we continue to believe that IHL , international law including IHL , fully covers these systems and is sufficient to regulate weapon systems that enjoy a high level of automation and also potential lethal autonomous weapon systems . They do not need any adaptation , modernization or to be adapted to any specific features of these weapon systems . During the ten years of the existence of the GGE , we have not heard what makes this category of weapon system so special in comparison to other weapon systems in the context of the application of international humanitarian law . As we already said , on the contrary , we came to the conclusion that it is current international law and its principles and the norms of IHL that are directly applicable to these weapon systems and these are the norms that should be used when we regulate these systems . And what do we understand when we think about such limitations ? If we reduce all of this to very simple language , then we are talking about the unacceptable nature of indiscriminate , unproportional use of lethal autonomous weapon systems and the use of such weapon systems against civilians and without taking any means of precaution to protect civilians . Also when we say that , we mean any military application of lethal autonomous weapon systems that is not carried out in line with the principle of proportionality with the military necessity and the harm that is inflicted . Also we believe that the adoption of any decision on the usefulness , the forms and means of using lethal autonomous weapon system is something that is done by human being , the human being that is planning the military operation and preparing the scenario for the use of such weapon systems . But these are questions related to accountability . So as you can see , all of the things that I mentioned covers all of the bullet points that are listed in your document and also it is fully in line with the understandings that were reached by the GG . And moreover , do not go beyond the framework of existing IHL . These are the fundamental principles and norms of international humanitarian law that apply to all types of weapons . Moreover , the number of parties to additional protocol 1 , 1977 to the 1949 Geneva Conventions shows the universal nature of the relevant obligations . And we would welcome the expansion of this list of parties including those who are parties to the CCW . Moreover , the obligations referred to above are considered by a number of states including the countries that have not joined the document that I mentioned and I am referring to additional protocol 1 . They are considered by those countries as norms of common law that will be or should be applied regardless of the fact whether states are parties to AP1 or not . Now , in this context , if we are talking about the applicability of international humanitarian law , any possible restrictions related to lethal autonomous weapons systems , we must refer to Article 36 of AP1 that also imposes relevant limitations on states ' parties as they develop relevant weapons systems . In all of this , we must point out that in itself , Article 36 of additional protocol 1 does not provide for any automatic prohibition of weapons systems as being noncompatible with the requirements of IHL due to the objective impossibility to foresee and take into account all possible forms of ill use of such weapons . We believe that the risk of any abuse in this connection , regardless of the level of autonomy of a weapons system , can and should be evaluated through the use of other procedures that provide for , among other things , personal accountability for the act committed . And yet another very important point related to Article 36 , the Article does not contain any provisions how legal reviews should be carried out . And it does not place on states , does not oblige states to publicize the results of such reviews or provide any information to anyone in this regard . If we talk about questions or accountability for the design and use of lethal autonomous weapons systems at all stages of their life cycle , and this is yet another category of limitations . Then here , as was confirmed by this GGE on numerous occasions , the responsibility lies on the shoulders of states as well as on the shoulders of individuals , including those who designed or manufactured the system , that those who use these systems within the functions that they have or those who develop these systems . We once again would like to say that the responsibility directly for the use of lethal autonomous weapons systems in line with IHL is on the shoulders of the public official that sets the objective for such weapons systems and gives the order for their use . We would like to stress that this approach is applicable to all weapons systems , means and methods of warfare without any distinctions and without separating any category of weapons systems and placing it in a separate group , giving it some form of an exclusive status . So the justifications for preventive ban on lethal autonomous weapons systems that are being proposed by some Delegations on the basis of morality or ethnic considerations related to IHL are fraught with the unnecessary fragmentation of the existing international legal regulation system and inevitably would lead to artificial breakdown of weapons systems into good systems and bad systems . And here we believe that international law including IHL is fully applicable to lethal autonomous weapons systems and does not need to be adapted to these weapons systems . In the same vein , in light of the arguments that we just made , it will be very difficult to talk about specific situations related to the use or development of lethal autonomous weapons systems due to the absence of a common understanding of what such weapons systems represent . In order to be able to have a clear discussion of these issues , we must have such an understanding . Otherwise , we will once again be talking about different things , about different characteristics , about different systems and about different cases for the development and use of such weapons systems and also about different cases of the application of IHL to such systems . Our Delegation would like to avoid that . Thank you .",Eastern European States,Yes
NORWAY,15:53:15,2024-03-05,0:04:15,"Chair , Norway would first of all like to thank you for compiling the bullet points on the screen regarding which elements and characteristics which would make laws incompatible with IHL . There are many relevant points on screen and they will serve as a good basis for our discussions of the application of IHL to autonomous weapons . And hopefully also contribute to elaborating language that could be included in our eventual recommendations on elements of an instrument . My Delegation should like to make some very general comments on our view of the application of IHL to autonomous weapons and then try to relate those to some if not all of the bullet points on the screen . Among other things , the compatibility of autonomous weapons systems with IHL depends on the level of human involvement throughout the whole life cycle of a weapons system . Systems operating outside of meaningful human control which , for instance , would prevent an operator from deciding or altering the parameters of a system at any given time would in our view be incompatible with IHL . Now , both formulations in the first bullet point would contribute to clarifying the necessity of human control with perhaps the second option signifying somewhat lower threshold . And the and that is a general point on the points that I should like to make is that under several of the points we find that some of the formulations are not really in conflict with the alternative formulations , but they seem to elucidate different sort of aspects of the concept under discussion . And let me go to one of the examples where a system would not be compatible with IHL if it is incapable of distinguishing between civilians , enemy combatants and combatants or the combat or an able to operate in line with the central principles of IHL distinction , proportionality and precaution . The use of weapons systems must be attributable to humans , not to machines . And that leads me to bullet point I think it is number 4 where it appears to my Delegation that the alternative formulations here , they do not really express two different views , but they express , well , differing views but not differing but non-conflicting views or elucidations or how to apply the concept of distinction to autonomous weapons systems . And as such , both of these would sort of help to elucidate what we are trying to do and it is not really it would be hard to make a choice between them as it were . The weapons systems compatibility with IHL will also depend on how the weapons system is used and under which circumstances . That is the importance of considering measures that would put in place limits to the duration and scope and scale of operations where such systems are used and ensure that the operators have a full understanding of how the weapon operates within its environment . A weapons system depending on , for instance , machine learning technology opens a whole range of ethical dilemmas and uncertainties about its ability to fully assess the complexity and changing dynamics of a battlefield . It is therefore essential that safeguards are put in place to ensure that the effects of such weapons can always be predicted , understood , limited and controlled . Now , in general , Norway holds and I think every state in this room holds that any lawful weapons system must be capable of being operated in accordance with IHL and that is being discussed or noted in the well , there is a lot of bullet points but it is the bullet point with the footnotes 14 and 15 and also to my Delegation's mind , these are the language that Norway has used is generally otherwise incapable of being used in accordance with IHL but I think it is fair to say that the other formulation of incompatible with any other treaty or customary law rule of presumably of IHL also helps to elucidate the concept of being incapable of being used in accordance with it . So it is hard to make a choice and I think both sort of formulations are helpful here . That is the first few points we would like to make . Thank you .",Western European and other States,Yes
SINGAPORE,15:57:48,2024-03-05,0:01:17,"Distinguished Chair , we thank you for your efforts to steward the important work of this group and the substantive progress that we have all seen over the past few days . As a starting point , there is consensus at this UNGG on laws that the use of laws must comply with IHL . Turning to the question on what elements or characteristics would make a laws incompatible with IHL , we would agree firstly that laws that are inherently indiscriminate and that cause superfluous injury or unnecessary suffering are incompatible with IHL . We would also agree that laws that are incapable of complying with the principles of distinction , proportionality and precaution are by definition incompatible with IHL . Our Delegation also agrees that laws with effects that cannot be anticipated and controlled are incompatible with IHL . We would also agree that the elements that would make a laws incompatible with IHL would include the absence of the system being located within a responsible human chain of command . Finally , we agree that an element that would make a laws incompatible with IHL would be its incompatibility with any other treaty or customary law rule . Thank you , Chair . Thank you for your intervention .",Asia-Pacific States,Yes
ISRAEL,15:59:21,2024-03-05,0:06:19,"Mr. Chairperson , I thank you for giving me the floor . Our Delegation sincerely appreciates the excellent points , questions and tools presented during these discussions . Our Delegation wishes to share its views on the elements and characteristics that will render laws incompatible with IHL . As we have discussed , this principle point over the years in the issue remains at the very heart of our debate . The Delegation of Israel fully acknowledges the well - known and established limitations imposed on weapons under IHL . First and foremost , there are two general rules that apply to every type of weapon . The prohibition on weapons calculated to cause injury or unnecessary suffering as well as the prohibition on weapons that are inherently indiscriminate , that is , weapons that are incapable of being used discriminately . Consequently , falling into one of these two categories will render a weapon system unlawful per se . This applies also to laws . For this reason , these two general rules ought to be part of our expertise - based discussion which Israel welcomes . We will , however , suggest clarifying the inherently indiscriminate formula to the clearer formula that various states are using in practice of "" incapable of being used in a discriminated manner . "" Another element that was already agreed upon by consensus in previous reports and in the 11 guiding principles refers to weapons which are otherwise incapable of being used with IHL or as the US and Switzerland better frame it , weapons that are incompatible with any other treaty or customary law rule . In the context of laws , this notion will accommodate with other IHL rules that categorically prohibit certain types of weapons such as CCW protocols or other treaties and customary rules as applicable to each state . In our discussions , we should be very careful not to conflate categorical prohibitions with targeting law or other IHL rules , particularly pertaining to the ways weapons are used in specific contexts . This would be wrong both legally and practically . For example , proportionality in attack is by definition a context - dependent as it requires considering the military advantage and the incidental damage to civilians in each and every case . As a context - dependent rule , it would be wrong to frame proportionality as a categorical prohibition In addition , it is critical to distinguish on the one hand between primary rules of IHL including categorical prohibitions of weapons , targeting rules and other legal rules and on the other hand , legal or practical aspects which are not by themselves primarily IHL rules . This includes issues such as control , responsibility , foreseeability , predictability or reliability While some of these concepts have significance in other fields of law such as the law of the state's responsibility or the international criminal law or have a practical meaning in the implementation of IHL , treating them as IHL rules or even framing prohibitions while using them would be wrong on many legal and practical levels . Specifically , with regards with categories involving the term control , human control , it is not a overreaching requirement under the IHL . Moreover , after many years of deliberations , we all know that the meaning of the term control in the current context remains unclear in a matter of debates in both IHL terms and the discussions within this forum . It is not coincidental that the forum agreed last year to include the control element in a positive framing without the qualification of human control , thus allowing a more comprehensive discussion on the necessary human interaction to ensure the compliance with IHL rather than conclusively identifying a level of human interaction that deems a system unlawful per se . This approach encourages a more nuanced exploration , a topic on which we might provide further elaboration in our statement addressing the following question as it might be more pertinent in that context . We are open to further discussion on these concepts , but this needs to be done in the right framework rather than in the context of legal prohibitions . Recognizing that there is a sorry , there is no one size fits all set of requirements for every weapon system , Israel believes that determining the appropriate level of human machine interactions and related subcategories should be approached in a more nuanced manner . I thank you , Mr. Chairperson .",Western European and other States,Yes
JAPAN,16:05:54,2024-03-05,0:02:38,"Thank you , Mr. Chairperson . I would like to make comments on the bullet points that you suggested in terms of incompatibility of IHL . I think the third bullet , inherently indiscriminate and the fourth bullet , distinction , proportionality and precaution and in the eighth bullet unnecessary sufferings . I think those terms are not problematic at all in terms of compatibility , incompatibility of IHL . As for the other bullets , I think we need to have more careful considerations from this point of view and I recognize in particular for the first and the second point , that is regarding the human involvement . Those two points are very important topics in our discussions and I would like to make two points for future discussion on this issue . First , ensuring the involvement of human beings who can be held accountable under IHL is essential for the use of weapon systems in compliance with international law , especially IHL . And the second point is it is important that humans are involved responsibly throughout the weapons life cycle and especially that such weapon systems should be used under the responsibility of the human command and control . Indeed ; there is consensus among many countries on the importance of the elements of human responsibility . I think we believe that it is necessary to deepen the discussion on how to secure these two important points in concrete terms in future discussions . Thank you .",Asia-Pacific States,Yes
FRANCE,16:08:47,2024-03-05,0:03:41,"Thank you , Chair . And we would like to thank you as well for the high quality of the dialogue that you have enabled for these relevant issues that you have proposed which have allowed us to have this rich dialogue . And now in front of us we have the difficult task of finding areas of agreement and disagreements and you have all our supports in this endeavor . Well , to begin I would like to provide some general considerations about the implementation of IHL on the matter at hand . Application of IHL , existing IHL to weapons systems based on emerging technologies in the area of laws is truly at the very heart of our work in this GGE . The first of the 11 guiding principles that we collectively developed points out that international humanitarian law continues to be fully applied to all weapons systems . And so our main goal must be to ensure that the development and the use of future weapons , those using autonomy included , are carried out in full respect of existing IHL . To do that , two key principles that arise from the rules of IHL must guide our work . First , the use of lethal weapons systems that include autonomy must be under human control and accountability in this responsibility must be called on if there is a severe violation of international humanitarian law . And the second principle , we must have appropriate human control guarantees that could take various forms and be applied at all stages of the life cycle of a weapon in order to ensure that the use of future weapons systems including weapons systems using emerging technologies in the area of laws remain in line with international humanitarian law and under responsible human control . In order to ensure that IHL is fully respected , we must ensure that the use of these weapons systems and the human control respect the principles of the distinction of proportionality and precaution considering the particular circumstances that of each attack . And that means maintaining sufficient human control . That means that human control must be the only person responsible for deploying a weapon system based on emerging technologies in the area of laws . Human control must also continue to define and validate the missions that are entrusted to this type of weapon system by defining the spatial framework of use , the temporal framework of use and the appropriate regulations . The appropriate level of human control must be assessed on a case - by - case basis and pursuant to the system being considered in order to ensure effective human control , it will be essential to have proper training and operational skill training to have proper understanding of the operators and the command of the system's capacity , its effects and how it interacts with the environments . Thank you .",Western European and other States,Yes
GERMANY,16:12:37,2024-03-05,0:02:46,"Thank you , Mr. Chair . In the case of a fully autonomous weapon system , it is Germany's view that it cannot be determined whether it can be employed in line with international law because its actions are not predictable . In this particular case , it is already the system as such that is incompatible with international law . We would , therefore , support the first option in the first bullet . With regard to the other bullets , it is fundamental that the weapon system itself can be used in a way that is compatible with the rules of international law , that is in particular that it is capable of complying with the principles of distinction , proportionality and precaution . Furthermore , as any other weapon system , also those weapon systems of concern to us today may not be constructed in such a way as to cause super injury or unnecessary suffering . Finally , indeed , we have to ensure the chains of responsibilities are not lost by the use of autonomous weapon systems . As it is not the laws as such that renders the system incompatible with IHL but its use , we would address the question under which circumstances its use is illegal when we discuss the next sub question . In Germany's view , the use of the system is incompatible with IHL if the system or its effects cannot be directed at a specific military objective , including if it employs a method or means of combat which cannot be directed at a specific military objective , or if it contravenes any other substantial provision of IHL , eg , prohibition of unnecessary suffering and superfluous injury , prohibition to attack persons or the combat . Germany aligns itself with subbullets 3 , 4,6 , 8 and 9 and 10 . It also supports subbullets 2 and 7 which are in our opinion a consequence of the aforementioned rules of IHL . To the extent that meaningful is equivalent of appropriate control , Germany can also support subparagraph 1 in that regard . Allow me to particularly highlight our support for bullet 7 , option 1 , effects cannot be limited , anticipated and controlled as layout in the working paper submitted by France , Germany , Bulgaria , Denmark , Italy , Luxembourg and Norway . By contrast , Germany does not consider laws directed against human beings per se incompatible with IHL as suggested in subbullet 5 . As to subbullet 11 , Germany is not entirely sure what is meant here since precluding is a rather general wording . To us the point of reference is not clear . In any event , Germany agrees that human responsibility for decisions on the use of weapon systems must be retained over the entire life cycle . Thank you .",Western European and other States,Yes
CUBA,16:15:40,2024-03-05,0:03:40,"Thank you , Chair . To address your questions under the application of IHL including the concept of human control , judgment or involvement , we would like to point out the following . For our Delegation we cannot limit the scope of the discussions and curtail it only to IHL . Autonomous weapon systems and semi-autonomous weapon systems must be considered in the context of the observance of international law which means that all and any autonomous weapon that does not meet the provisions of international law including IHL must be banned even before they begin to be developed and used in large scale and to be deployed . This is a preventive approach based on the principle of precaution . Systems that do not guarantee significant human oversight nor do predictability , trustability , traceability , reliability and cannot be explained cannot be developed either . Sir , the use of completely autonomous weapons raises challenges for the fulfillment and the observance of the standards and principles of international law that cannot be guaranteed as these weapons could be used counter to the principles of sovereignty and territorial integrity of states which are enshrined in Article 2 of the United Nations charter . The principle of distinction under IHL demands that human beings that resort to force draw a distinction between those participating in the hostilities and that as such can be attacked and all others including civilians , combatants , persons or to combat and other protected persons with laws this principle cannot be insured . These weapons systems can perpetuate and amplify biases including those that are racial or gender biases depending on the data set that they use as a foundation . As we begin our discussion with a view to highlighting the various elements of an instrument we would like to reiterate our concern over the use of these weapon systems and the dehumanization of conflicts . In our view machines cannot replace the human beings in the most important decisions of war . There must be a prohibition of all those that do not have human control over these aspects . The degree of autonomy and lethality are basic characteristics that ought to guide the prohibition or regulation of autonomous weapons . Qualitative judgments which can only be made by humans are of key importance in the terrain of military operations as they provide greater guarantees and fulfillment of international law and they guarantee the individual responsibility as well as states' responsibilities . For our Delegation the laws that cause unnecessary suffering have indiscriminate effects and can produce generalized long lasting and serious harm to the environment must be prohibited and as such they are not compatible with current IHL . Thank you .",Latin American and Caribbean States,Yes
INTERNATIONAL COMMITTEE FOR ROBOT ARMS CONTROL,16:19:41,2024-03-05,0:01:20,"I will now give the floor to ICRAC . Thank you very much , Chair . ICRAC generally agrees with most of the bullet points which are listed . Just wanted to add one to those points and this is a point on incompatibility with rule 88 of customary international humanitarian law on the right to non-discrimination to repeat again it is incompatibility with rule 88 of customary international humanitarian law on non-discrimination . Rule 88 on customary IHL prohibits adverse distinction in the application of IHL based on race , color , sex , language , religion or belief , political or other opinion , national origin , et cetera . Chair , stakeholders have noted that the development and use of certain laws may exacerbate gender and racial discrimination . It is the submission of ICRAC that such laws would be incompatible with international humanitarian law and this point because it is rarely perhaps conversed is a point that ICRAC emphasizes at this point . Thank you , Chair . I would like to thank you for your intervention .",Non-applicable,No
AUSTRIA,16:21:09,2024-03-05,0:04:16,"We just also wanted to share I am sorry . We just also wanted to share some views on this list . Preliminary I can say that we are fully aware that this is just a listing of answers that you have received your questions and that there are some other questions that go into a similar direction . But at the same time we also have to stress out that this is a little bit of an apples and pears list and especially the chapeau creates some problems . I think some delegations have already pointed to that and I will have to go a little bit longer to explain why . The first thing is what we are doing here , at least in our view , some other delegations might have different views are three different things . First , of course , we look into how existing IHL applies . And this are , of course , the things that are core elements of IHL . We see them up there to some extent , the superfluous injury , unnecessary suffering , distinction proportionality precaution and so on . How do these apply in a context where we have these kind of weapons ? And if we go to this , we also have already quite a common understanding or many delegations are supporting that these kind of weapons that have these problems in their design , in their development and so on when we are speaking about autonomous weapons systems should be prohibited . The problem is this is not the only thing that we are doing here . What we are also looking is how does IHL apply , how can we specify how IHL applies and solve some of the problems and question marks surrounding these kind of weapons . And this is not only a kind of list like this . It is also related to the use . It is also related how those kind of weapon systems are managed , how they are designed and this relates also to issues then like accountability , predictability , reliability and so on . And these are , of course , not core principles of IHL that render a weapon systems incompatible with IHL as such . It is highly related also how it is used in the end . And this is another dimension that we have to look at that is not necessarily fit to be used in such a list . In our view , this also relates to human control . We see human control here as the first point operating completely outside or the absence of meaningful human control . In the essence , we could agree with this . But as the US also has pointed out , it is not very clear as it is . It is not a category of existing IHL . So what we have to do , we have to fill it with substance . And this is , for example , one of the things that we tried to do in our working paper of last year and the result that will hopefully at some point will come to light is that human control has to be built . It has to be achieved by setting specific measures . It is not just there out of the blue . It is not jumping out of the box . You have to do something to achieve human control . And so it also does not really fit under a chapeau like this . And the third thing , and this is also a problem , we are also having kind of prohibitions that are not necessarily derived from IHL . I know that this is not very popular . But it also derives from human rights law , from ethical principles and it can also be completely new law . And before people are completely shocked by this , I want to refer to the preambular of the CCW that clearly reaffirms the need to continue the qualification and progressive development of the rules of international law applicable in armed conflict . And this is also something we could do . We are aware that it is not widely popular , but this is also one of the things that we are doing here . It is also not an application of existing international humanitarian law . And this is kind of the weird situation that we are in here with this list in front of us . Having said this , there are several points that we could agree with , but others are having the specific problem that they need to be specified . They need more context . They need more flesh surrounding it . And in other cases , we just have to put them under a different heading . Sorry for being so direct and thank you . I think I have some other points later on as well . Thank you for those initial comments .",Western European and other States,Yes
ICRC,16:25:39,2024-03-05,0:04:36,"Thank you , Chair , for giving us the floor . In terms of the characteristics that would make an autonomous weapon system incompatible with IHL , on the first bullet point regarding human control , we note that IHL does not necessarily demand human control over the weapon system itself at all stages , but IHL does require control over the weapon's effects . And this concept of human control over effects or over the use of force should underpin the drafting of any instrument . For us , it is what needs to be preserved . And the way to preserve it is to prohibit certain autonomous weapons and restrict all others . Then looking at some of the other bullet points , of course , like any other weapon , autonomous weapon systems will be incompatible with IHL if they do not comply with existing IHL rules that apply to weapons , means and methods of warfare . And I think this is well recognized in a number of bullet points on the screen , explicitly in the second last bullet point , but also in those referring to weapons that are inherently indiscriminate or cause superfluous injury or unnecessary suffering or widespread long term or severe damage to the natural environment . So undoubtedly these elements would make an autonomous weapon system incompatible with IHL compliance , but we consider that the value of this group's discussions lies in moving beyond a restatement of IHL rules to elaborate how these rules and how international law more broadly specifically apply to constrain the development and use of autonomous weapon systems and to identify also where these rules should be strengthened . And I echo the comments just made by Austria in this respect . So in this respect , we find the seventh bullet point particularly helpful . It seeks to translate IHL's requirements into a prohibition on autonomous weapons , the effects of which cannot be understood , predicted and explained . In our view , this wording , it reflects IHL's requirements for weapons users to anticipate and limit and control effects and we note that is alternative wording there . But it would do so in a way that offers more concrete guidance for the design and use of autonomous weapon systems . We think that this kind of formulation would assist in addressing certain types of particularly problematic autonomous weapon systems including those that rely on certain AI or machine learning techniques that lead to the kind of opaque or unpredictable functioning that was noted this afternoon by the Distinguished Delegates of Ireland and Norway or those which change functioning after a review or during use . Chair , considering bullet 5 , referring to autonomous weapon systems designed to target humans directly , we struggle to conceive of an autonomous weapon system like this that would not pose a real risk of IHL violations . As was highlighted earlier by the representative of Ireland , autonomous weapon systems are unlikely to be able to account for all the contextual signals that indicate that a person is protected from attack . We would also like to note that IHL requires preserving a possibility for adversaries to surrender . So employing an autonomous weapon system that would not be capable of identifying an intent to surrender would violate that prohibition on the denial of quarter . Finally , Chair , we note that this topic is focused on IHL but at the same time and similarly to the comments just made by the Distinguished Delegate from Austria , we strongly encourage attention to ethical concerns within this topic because these concerns are at the heart of debates about the acceptability of autonomous weapon systems . Ethics have always been a driver for the evolution of international legal rules in warfare and they should not be viewed as an afterthought . They have been explicitly recognized as a guiding principle for the work of this GGE and their role is reflected in the Martens clause . So the ICRC's view is that ethical concerns arise with all autonomous weapon systems that endanger human beings but they are particularly acute when it comes to autonomous weapon systems that target human beings directly as referred to in bullet 5 . I thank you , Chair .",Non-applicable,No
EUROPEAN UNION,16:30:31,2024-03-05,0:02:58,"Thank you , Mr. Chair . Since this is the first time that I take the floor , I would like to congratulate you on the assumption of your duties and assure you that you can rely on the EU full support . The EU remains committed to pursue the efforts in the GGE . We have a view to ensuring that the outcome reflects the necessity of compliance with international law , in particular international humanitarian law taking into account relevant ethical considerations . Let me start with general remarks on the compliance with international humanitarian law and some of them will refer also to the ballots presented on the screen . The EU emphasizes that human beings must make decisions with regard to the use of lethal force , must exert control over lethal autonomous weapon systems that they use and remain accountable for decisions over the use of force in order to ensure compliance with international law , in particular IHL , taking into account ethical considerations . Those who plan , decide upon and carry out an attack using a lethal autonomous weapon system must , therefore , ensure that the weapon system and the way it is used will preserve a human being's ability to make the necessary legal judgments and thereby ensure compliance with international law , including IHL . We support also the reference to the need to ensure that the development , production , deployment and use of emerging technologies in the area of laws must be in compliance with international law , in particular IHL . Also appropriate level of human control and judgment should be retained during the whole life cycle of the weapon system to ensure compliance with international law , in particular IHL . Moreover , the EU supports the so - called two - tiered approach to laws . A distinction should be made between those weapon systems that cannot be used in accordance with international law , in particular IHL , which states should commit not to develop , produce or use and systems that include autonomous features requiring regulation to ensure compliance with IHL and other applicable international law . Let me also make a remark on human responsibility . We recall that states bear a fundamental responsibility to ensure that the development , production , deployment and use of emerging technologies in the area of laws will be in compliance with international law , in particular IHL and that human responsibility for decision on the use of force must be retained . Thank you , Mr. Chair .",Non-applicable,No
RUSSIAN FEDERATION,16:33:43,2024-03-05,0:05:39,"Thank you very much , Distinguished Chair . At the outset , I would like to apologize for having to take the floor once again , second time , but we would like to react to one comment that was made by the Delegation of Germany . A comment about the fact that it is very difficult to see whether lethal autonomous weapon systems are employed in line with IHL because such systems are unpredictable . We , once again , are hearing about this issue of predictability or non-predictability in the GGE as an excuse explaining why this weapon system deserves special attention or a creation of a separate exclusive group for this type of weapon system . We simply do not understand this argument . We are not convinced at all because , in essence , it is not a correct argument using this whole notion of predictability or unpredictability . It is not a legal notion , this notion of predictability . Predictability is insured by relevant norms and principles of international humanitarian law . The relevant understanding on this issue has been enshrined by our group in separate reports and those understandings relate to obligations related to the need to hold legal reviews and to ensure the necessary control and accountability of the designers and those who give orders to use such weapon systems , direct operators of such systems . Moreover , in our last year's report , the GGE referred to specific limitations that can be used for such systems and also to need relevant real training of operators of such systems . All of these measures , measures of precaution , we can call them as such , can ensure the predictability in the use of such weapon systems . This is indeed the objective of the relevant principles and norms of international humanitarian law and the situation here is exactly the same as applied to any other technologically advanced weapon systems and we have dozens of examples of such systems . However , as far as those weapon systems are concerned , we do not see any need to discuss these questions yet in connection with weapon systems with laws , technologies that still do not exist and we are still unable to give a definition of such systems . Now we see that there is some need to place these weapon systems in some type of separate category only because it seems to us that they may be used in an unpredictable manner . So we believe that these arguments are contrived and they remind us of an attempt of setting a task when we know what the answer already is . And this runs counter to the understandings that have already been expressed by the group in order not to inflict any harm or create obstacles to technological progress and to need to thoroughly analyze the existing norms and rules of international humanitarian law and other international legal obligations in the context of weapon systems . Thank you .",Eastern European States,Yes
UNITED KINGDOM,16:39:58,2024-03-05,0:03:20,"Thank you , Mr. Chair . And thank you for sharing this text which goes to the heart of the first element of this debate , that is if we frame this in line with the two - tier approach , what would sit in the first tier . We can see that the discussion ensuing is extremely fruitful in identifying how we should focus our approach . We agree with the sentiment that the framing of this issue could be a little more precise than is currently captured in this text . As we are speaking about compatibility with IHL , we need to look at the long established understanding and practice in relation to the determination of compatibility with the law . We are establishing the starting point here . We need to untangle the intent and the inherent incompatibility from incompatibility that might have an element of use . There is also the question of whether we are in this exercise and in this discussion addressing a pure question of the application of the law as it currently stands or whether we are seeking to extrapolate or even create new law . Bullet point 3 , talking about inherently indiscriminate weapons and bullet point 8 , talking about weapons which cause superfluous injury or unnecessary suffering are incompatible on the basis of the direct application of the law as it stands . The language applying the current law should be careful to translate it properly . Thus we need to look very carefully at the scope of rules , for example , in relation to environmental damage . Bullet points 1 and 2 which refer to meaningful human control and chain of commands are we think an attempt to extrapolate the law . While the final bullet point on attribution concerns the secondary obligations which fall from the requirements to ensure respect and state responsibility . Finally bullet 5 on targeting humans directly does not reflect any existing rule of IHL . There is separate work to be done on whether there is a case to create such a rule and it is clear that the views on that matter differ across this room . We would propose , therefore , that this would be a matter for a discrete area of work should this group deign for that to engage in that potential course . As this particular text risks conflating as such this particular text risks conflating inherent requirements of IHL with the behaviors that enable compliance with it . The Distinguished Delegate from Austria has usefully reminded us that there is scope for this group to both extrapolate and develop international law in this regard . We do not disagree . The elements on this text can be regated into the two - tier approach to do just that . It is using the chapeau in using the chapeau as the US suggests of laws incapable of use in accordance with IHL . We provide a firm category from which to launch the work on the question of necessary human involvement , restrictions on types of target and other regulatory measures as contemplated by the two - tier approach . Thank you , Mr. Chair .",Western European and other States,Yes
BELGIUM,16:43:32,2024-03-05,0:05:11,"Thank you , Mr. President . We would like to point out the core centrality of IHL and international criminal law as it relates to autonomous weapons . This centrality is the core of this discussion in my Delegation's opposition to matters related to these weapons systems . Belgium calls for a two - tier approach , first an explicit ban on certain types of autonomous weapons and the regulation of others such as an increasing number of Delegations within this group of experts have also said . Belgium's understanding of the two - tier approach acknowledges that all autonomous weapons systems are not equal as regards the legal and ethical potential implications by distinguishing systems that should be prohibited from those that should be regulated . The two - tier approach tries to create a more nuanced framework , a more efficient framework to meet the challenges of autonomous weapons systems . Belgium underscores the importance of significant human control on autonomous weapons systems and identifies the interaction between human and machine as essential in guaranteeing compliance with international human law , humanitarian law and international human rights law and international criminal law . Belgium recognizes that the interaction between humans and machines can take different forms and can take place at different stages of the life cycle of a weapon and so the regulatory and operational framework should be based on the process and it depends on the context , including the technical characteristics of the system , of the environment in which this is being used as well as the type of interaction between the human and the machine which should have significant human control . According to Belgium , the two - tier approach is based on a prohibition of autonomous weapons systems focusing on complete prohibition of a system that would be in IHL because it could cause suffering because it has indiscriminate effects or that they were created to cause or we might expect that they cause extended long lasting and serious damage to the natural environment as well as autonomous weapons systems that cannot be used in keeping with IHL . The latter type of weapon includes those who were created or used so as to ensure that their effects are not understood or explained well enough beforehand as well as those that do not have significant human control over their function such as the identification , the selection and the engagement of the target . The regulatory tier of the approach is for all autonomous weapons systems that are not completely prohibited and guarantees compliance with the humanitarian law including IHL and its fundamental principles . The distinction of proportionality and precaution means that we have to have guidelines and clear rules when it comes to requirements for human behavior during the development , the deployment or the use of these systems by focusing on maintaining significant human control but also in terms of responsibility and accountability throughout the entire life cycle . With that in mind , my Delegation supports the following parts . According to my Delegation , a weapon system that meets sub item 3 , 4,5 , 6 , 7 and 8 is by definition a system that is incompatible with IHL regardless of its level of autonomy . Autonomous weapons systems that on the other hand are covered by sub items 1 , 2 and the second part of the 7th item are more specifically related to autonomy and as such more relevant to the debate of the G but my Delegation supports these sub items as well . Lastly , my Delegation supports the item on the bullet point on the legal responsibility that the last one with which in and of itself is not incompatible with IHL but with the state's obligations under international law in broader terms . The state must guarantee accountability for the conception , the development , the deployment and the use of autonomous weapons systems in keeping with their obligations under international law and IHL . My Delegation also highlights the importance of taking into account the guiding principles B and D regarding the developers and manufacturers of these autonomous weapons systems given that the responsibility is on them for the conception and programming stages of an autonomous weapon system . This is particularly relevant for the problems related to the data biases that could affect decision - taking and the ill use of data or improper programming . Thank you .",Western European and other States,Yes
INDIA,16:49:01,2024-03-05,0:01:25,"Thank you , Mr. President . This is a very useful compilation and thank you for putting this up . It provides us a general idea of the spectrum of issues we are dealing with when we approach the question that we are discussing from an IHL perspective . It is also one of the alternatives that is available to us for defining the scope of an instrument that we might consider . We support this approach . I have three points , one general and two specific . The general point is that we have no difficulty in accepting well established principles of IHL . However , our position on the rest will be determined on how the obligations and general commitments of an instrument are framed , that is , as prohibitions or restrictions or positive obligations . The two specific points are with reference to the bullet points number 1 and number 5 . We can take a more positive view of terminology such as human control , meaningful or otherwise , if the related obligation is framed positively . The second specific point is that the reference to targeting humans directly needs to be reconciled with the existing law of distinction and the provisions therein about combatants and civilians . Thank you , Mr. President .",Asia-Pacific States,Yes
SWEDEN,16:50:42,2024-03-05,0:02:54,"The floor is for the Swedish Delegation . Thank you , Mr. Chair . Sweden reiterates that this group has acknowledged that international law , in particular IHL , applies to laws . IHL includes rules and principles that de facto prohibits the use of certain weapons and regulates the use of others . Some Delegations in this room wish to create new rules of IHL for laws . Others wish to clarify how existing IHL applies to laws . In this discussion , we think it is useful to be clear about when we are talking about how we understand current applicable IHL and when we are talking about how we think that the law should develop . Sweden understands that we are under this point discussing how current IHL applies to laws . As mentioned yesterday , we support the two - tier approach indicating that a distinction should be made between those weapons systems that cannot be used in accordance with international law , in particular IHL , and systems that include autonomous features which should be regulated in order to ensure compliance with IHL and other applicable international law . Since we understand that there is wide support in the room for the two - tier approach , it would be interesting also to hear from you , Chair , how you understand the questions on topic 2 , application of IHL to relate to the two - tier approach . We also have a few comments on the proposed bullet points . In line with some other Delegations who have mentioned the first bullet point and the second one as well , which relate to human control , they are acceptable to us as such , but they are not necessarily a part of the IHL . We prefer the wording operating completely outside human control , just for the record . Bullet point 3 is , of course , fine with us , acceptable as well . When it comes to bullet point 4 and bullet point 7 , I believe my Distinguished Colleague from Norway put it very eloquently , there are very good elements in there and they are not necessarily opposing one another , but we wonder if bullet point 6 will not encompass all three of these elements in an easier way . Bullet point 5 , like mentioned by other Delegations as well , goes beyond IHL and would not be necessary in this listing . The other bullet points are acceptable to us as proposed by you in general , but it all kind of boils down to the question how they relate to the different tiers of the discussion . Thank you , Chair .",Western European and other States,Yes
PAKISTAN,16:54:46,2024-03-05,0:06:31,"Thank you , Chair . Chair , on the the questions that you have posed before delving into that , I would like to just add a couple of general comments on the debate that is taking place here . We fully agree with , as you have described , that we would get into the form later on how to formulate these suggestions . At the same time , while taking into account the mandate in the mandate , we have been asked also to look at the existing example of our convention and protocols . So when we are working on different formulations , prohibitions or regulations or compliance with IHL , we have to draw constantly guidance from what is in front of us on that count . So on this topic , we understand that we have heard from this room many voices who consider that the first tier would only revolve around the application of existing IHL when we talk about the two - tier approach . Our understanding is that under this topic , while we are engaging on the subject of how the IHL would apply , that will not be the sole determination of the two - tier approach . The obligations in terms of in both tiers that would be contained therein May have other sources as well other than the application of IHL . So we would reserve the right to come to that at a later stage under other topics which will also contribute to these two tiers . Secondly , on the concept of application of IHL , we understand that this topic has been framed right now , application of IHL , but we very much share the point of view that was expressed by the Distinguished Delegate of Austria as well , that for us , IHL is not a static construct and we believe that one of the core purposes of CCW is the progressive development and continued codification of the international law applicable in armed conflict which is clear in our preambler as well . And this is also the examples that we have pursued while negotiating other protocols of this convention . If simply saying that IHL applies was enough , we would not have needed to deliberate and expand on the obligations relating to other weapon systems , for instance , in Protocol 1 where we talked about the effects of the non-detectable fragments or Protocol 4 in blinding laser weapons where we brought out additional effects of those weapon systems as well . So while some notions that appear on the screen as of now , we may not find those exact terminologies in the existing body of IHL . It does not mean that in order to comply with IHL , they cannot be brought up or they cannot be discussed . On the contrary , we believe that the challenges that have been posed by the IHL , we would need to delve deeper into these terminologies , let's say , predictability , understandability , explainability , traceability , all these concepts that have been discussed time and again in our previous work which are relevant to the applicability of IHL . Then we would like to express our endorsement with most of the principles that you have captured on the screen . In this context , I think human control , element of human control , it is important for our Delegation . In our working paper , we outlined that any weapon system that takes decision on the use of force without human control is something that would lead to incompatibility regarding the application of IHL . But we are also open to the idea of mentioning the meaningful human control , but we could have some additional benefits if we could specify how to arrive at that level of control as suggested by our Austrian colleague earlier in the discussions as well . Then we have some additional suggestions as well that were contained in our working paper . I think that should be considered in our setting here . For instance , a weapon system that is not able to take all feasible precautions to protect civilians and civilian objects during an attack . That is an important rule in the IHL as well . Then another one which causes incidental harm to civilians and civilian objects that exceeds the direct military advantage anticipated . We believe that these two important rules are also they have particular significance in the context of lethal autonomous weapon systems . They could be considered here under this topic . Then lastly on the question of state responsibility and individual responsibility , while we agreed in our guiding principles in 2019 that this responsibility and accountability will hold true in all cases , I think it is time now while we are drafting or attempting to draft elements of an instrument to expand on how to ensure that accountability . We would favor that there should be clear language towards that end that humans should remain responsible for and in control of any weapon systems relating to laws and states would be required to evolve effective oversight and redressal mechanisms for any suspected reported or documented violation . We believe many of the useful concepts were there also when we were negotiating the last year GGE's report . Unfortunately we were not able to capture them all at that time due to paucity of time . Now we have a longer mandate and we need to spell out in greater detail how to achieve that level of accountability and responsibility on this topic . Thank you .",Asia-Pacific States,Yes
SWITZERLAND,17:01:27,2024-03-05,0:05:59,"Thank you very much . Thanks , Mr. President . Like others I would like to thank you for yet another useful list . The starting point for us is that autonomous weapons systems that cannot respect IHL are ipso facto prohibited . The use of other AWS should be regulated notably to ensure that they respect IHL . It is therefore a very pertinent question what elements or characteristics would make an AWS incompatible . So like others have said before us , what we are doing here really is to identify the key components of the first tier , namely what should explicitly be prohibited . Another question was asked previously , what makes AWS so special that we would have to look more closely whether they comply with IHL . Well , we let machines do something that was originally done by human beings and this points to what our Austrian colleague has said before , how the system really is used in the end in the specific situation and it also relates to the words of our US colleague this morning , autonomy can be understood as a way of using it , the system . This is very significant . That is why we are here for ten years now . We have discussed this because it is significant development , significant for the CCW . To the specific bullets , some of the points on the list , they reflect clear and long - standing prohibitions under IHL , namely the prohibition of means and methods of warfare that are of a nature to cause superfluous injury or unnecessary suffering , the prohibition of the use of methods or means of warfare that are intended or may be expected to cause widespread long - term and severe damage to the natural environment , the prohibition of means and methods that are by nature indiscriminate , means and methods of warfare are by nature are those that cannot be directed at a specific military objective or whose effects cannot be limited as required by international humanitarian law and consequently are of a nature to strike military objectives and civilians or civilian objects without distinctions . So bullet 4 and partly bullet 7 could kind of be subsumed under the prohibition of weapons that are by nature indiscriminate . And then following this logic , it would also be incompatible with IHL if its effects cannot be limited , anticipated and controlled in the circumstances of its use , ie , the specific context where or when the system is used . And this would notably be the case if a system was operating completely outside human control or outside a responsible chain of command . And this is supporting points 1 , point 2 , but also most importantly bullet point 7 . This is the key issue at hand and we could not agree more with the ICRC which has referred to this as the added value of our group and the point made by our Pakistani colleague just a moment ago on the progressive codification which is a point we fully support and he made that point very eloquently just now . With regard to point 5 , our design to target humans directly , we would be hesitant to interpret the IHL prohibition so extensively as IHL does not prohibit the targeting of persons as such . IHL is clear , however , that parties to an armed conflict shall direct their operations only against military objectives which includes combatants . It is therefore notably prohibited to target civilians or combatants or the combat . And having said that , an oath designed and used to target humans poses serious questions , in particular regarding the risk of IHL violations . And this may deserve more policy and ethical reflections for an instrument if that instrument would go beyond what is strictly required by IHL . Then last but not least regarding bullet 6 , it is our impression that complying with these principles is rather a question of targeting law , ie , how a weapon is used . Of course , if a system would be designed in a way that it is not possible to direct it at a specific military objective or if it would invariably cause excessive collateral damage , it could be considered to be indiscriminate by nature . So those are some of the points that we wanted to contribute at this stage to this topic . Thank you so much . I would like to thank you for your intervention and your contribution to the discussion .",Western European and other States,Yes
UNITED STATES,17:07:39,2024-03-05,0:10:36,"Mr. Chair , we wanted to really react to the very good discussion today and really appreciate you for facilitating and guiding us towards a very substantive exchange . I think one point that we wanted to agree with was I think just said very well by our distinguished colleague from Pakistan . That we really need to delve deeper on a lot of these concepts and engage in more work . Also wanted to generally endorse Sweden's comment that we should be clear in our work about when we are stating existing law and when we are proposing new new law . That said , we do have some divergences from some of the discussion and we did want to record those . I think a general important principle for us is that people and the users of the weapons are the ones who must comply with IHL and IHL obligations . The weapons do not have legal obligations as such and we hear some people saying that the weapon must comply with IHL and we find this problematic because it seems to articulate requirements that no weapon has ever had to be subject to and it would be then a basis for outlawing many existing weapons . Of course , from our perspective , it does not make sense to interpret IHL to render unlawful many existing weapons that people are currently using without legal controversy . Although we see differences in how people understand IHL to apply , I really do want to emphasize we want to work through those differences by being more specific and granular and talking about how specific rules of IHL apply with regard to the use of weapons with autonomy . We think this specificity will be important for making sure we have consensus on meaning of the elements of the instrument and making sure we have an effective instrument that will can be applied and regulate state behavior . So now I will just proceed with some specific remarks on some of the bullets in addition to what my colleague noted as more general comments earlier . With regard to the bullets operating completely outside / the absence of meaningful human control , I think you know my Delegation's position on this . We would also agree with Austria that this bullet does not really fit here , right ? How you control the weapon system , you know , we see as a function of the use of the weapon and it is not an attribute of making the weapon intrinsically by nature prohibited . So favor moving the discussion on these aspects , you know , to the second tier of talking about use . Another point we would make is that from our perspective , every munition at some point operates outside human control . You know , there is always a point where we are not able to control the effects of a weapon and so we are struggling to understand this point that that would then be a basis for rendering weapon systems to be illegal . A similar point with regard to the next bullet and a responsible chain of command , again we see that as a function of how the system is used and not an attribute of the system . The IHL concept of responsible command and control relates to the people in the armed forces who are using the weapon , not the weapon as such . With regard to the bullet about cannot be directed at a specific military objective / cannot distinguish between military and civilian targets and persons or to combat , one comment we have is to delete specific before military objective . We do not see specific as necessary here and in our view it is consistent with IHL if the weapon can be directed at military objectives . We would object to the notion that the weapon needs to be able to distinguish between military and civilian targets and persons or to combat . No weapon has been able to do this . We think these are obligations incumbent on the users of the weapons to do so . So again , we would modify the language to talk about whether the weapon is capable of being used by a person to conduct an attack consistent with distinction of proportionality rather than having the weapon have to comply with the legal rule . With regard to the bullet about our design to target humans directly , we would agree with the Indian Ambassador's comment on this point . With regard to the bullet incapable of complying with the principles of distinction , proportionality and precaution , I first would like to associate our Delegation with the point that Switzerland just made that we see this language as emanating or connected to the notion of inherently indiscriminate weapons and then would make the same point that we have made that it is not the weapon that must complies with these principles and requirements but instead that the weapon is incapable of being used in accordance with IHL . We would prefer to add principles and requirements here when talking about distinction and proportionality in line with our past GGE language . I think another point we would make substantively here is to omit the notion of precautions and attack . You know , we see precautions and attack as a requirement emanating from the principle of proportionality rather than a freestanding principle . In addition , we have not understood the legal requirement to take precautions in planning and conducting an attack to be a basis for prohibition on a class of weapons . The requirement to take precautions is qualified by what is feasible which is a very contextual analysis and here I think our Distinguished Colleague from Israel made a very good explanation of the point of how some IHL requirements need to be based on the circumstances ruling at the time and we certainly think precautions fits in that category and it is thereby difficult to extrapolate that into a general prohibition on a class of weapons . With regard to the next bullet , effects cannot be limited , anticipated , controlled , et cetera , I think our general comment would be that we do not see these as freestanding requirements of IHL and we would urge that we try and like a colleague from Pakistan delve deeper into some of these requirements and how they connect with specific rules and principles of IHL and I will just illustrate how we have tried to do that in our draft Articles with the language autonomous weapons systems may only be developed such that their effects and attacks are capable of being anticipated and controlled as required in the circumstances of their use by the principles of distinction and proportionality . So we are trying to deal with the same concepts of anticipation and control but we are also trying to be more granular and to connect them with specific IHL rules and that is an approach that we think would be a useful approach to deepen our discussion . With regard to the next bullet , causes superfluous injury or unnecessary suffering , we think it would be very important to add being of a nature to cause here because simply causing superfluous injury or unnecessary suffering is not a basis for the weapon itself to be prohibited per se , rather it has to be of a nature to cause superfluous injury or unnecessary suffering . With regard to the next bullet relating to the natural environment , the US is not a party to the 1977 additional protocol 1 and has objected to assertions that this provision of AP1 relating to the natural environment reflects customary international law . Regarding the next bullet about general incompatibility with any treaty or customary law rule , I think this is a very good concept here . One comment is to insert the word "" applicable "" before "" treaty "" because states have assumed different treaty obligations . And then lastly , with regard to the last point , I think there should be we think there should be further clarification of this bullet . It refers to attribution and we understand the attributability of the conduct to a state or an individual to be different from the legal analysis of whether there is legal responsibility , ie , a violation or wrongful conduct . So recommend further discussion on this last bullet . Thanks so much for bearing through this long intervention , but hopefully it contributes usefully to our discussion . I thank you , Mr. Chair . I would like to thank you for going into detail on the text put on the screen . We have so far three more requests for the floor . Australia , Austria and the IGRAC .",Western European and other States,Yes
AUSTRALIA,17:18:42,2024-03-05,0:01:58,"Thank you , Chair . At the outset , I wanted to reaffirm my appreciation for the way in which you are conducting our meeting . This has been a very productive meeting thus far . We would firstly like to provide some overarching observations on the framing of this question and will engage with the specific points outlined and respond to the views of other Delegations in a further intervention . While we acknowledge many Delegations are seeking new prohibitions or limitations that go beyond existing IHL , clarifying and elaborating how existing IHL applies to laws is critical . My Delegation would endorse the preliminary comments made by the Delegations of the United States , Austria and the UK regarding the framing of this question . It makes sense to start with elaborating types of weapon systems that would be inherently unlawful because they are incapable of complying with IHL . We could then move on to Tier 2 , restrictions applicable to use of all other weapons . We would also fully endorse the suggestion to start with existing consensus language and build on it . Further , when discussing how existing IHL applies to laws , it is important to distinguish the rules and principles of IHL and what might be additional good practices or measures that help enable compliance with IHL . It is also necessary to distinguish those IHL requirements that are primarily applicable to the use of weapon systems and measures to be implemented in the design and development phase . We are still mulling over the specific elements proposed here and with your indulgence we would like to return to these elements in a follow - up intervention . Thank you .",Western European and other States,Yes
AUSTRIA,17:20:51,2024-03-05,0:02:44,"Chair and sorry for taking the floor a second time . We felt that we should clarify some of the elements of our statement from before also with regards to how the discussion has developed which I think is in a very good way . One of the points that have come up now out of the discussion is that this kind of elements that we are seeing here should form the first tier of the two - tier approach . In this we do not agree . There are several elements that should also be included here that are actually on the screen but need a formulation that is I have to reformulate . There was the notion by some Delegations that the first tier should be those kind of elements of IHL that are existing and that cannot be used in the framework of autonomous weapons systems . We believe that there are certain other elements that also should fall in the first tier as part of prohibitions and this should also include meaningful human control . There I have to clarify that what we meant with specifying it and making it a positive obligation is something that is more something that states can do is related to this . So there should be a prohibition . If there is no meaningful human control , it should be prohibited . But we also need to make very clear in possible instrument how this meaningful human control can be achieved , what kind of measures must be taken by states to achieve this so that this is not just an empty shell of a word but that it is actually filled with life and something that states can apply . Otherwise we are getting in the legal problems that actually many Delegations fear when we go into the human control debate . The second point is something that we could also see as a possible part of the first tier is a prohibition based on ethical elements . This might relate to something that you could explain like procedural element on how persons are engaged . This , of course , needs more discussion and it is definitely a difficult discussion . But the first tier and this is the main point of my intervention is not just only an explanation how existing IHL applies . It has much more to it and this is something that needs to be included as well and I think the Pakistani colleague and also our Swiss colleague have made excellent interventions in that regard as well . Thank you for that .",Western European and other States,Yes
INTERNATIONAL COMMITTEE FOR ROBOT ARMS CONTROL,17:23:42,2024-03-05,0:02:51,"Thank you very much again , Chair . My intervention at this point in time is just a reflection on some of the comments that have just been made by the Delegation from the United States . Particularly we agree actually and like this point which has been emphasized that when we are discussing laws it is important to not to use or to use phrases that seem as if , you know , machines bear obligations . On that particular point we really agree with the United States . Nevertheless , there is also something that has been said in this particular regard that we would like to seek clarification where the Delegation noted that there is always a point if I am to quote where we are not able to control the effects of a weapon we have questions regarding to that characterization , especially on the position of existing international humanitarian law . Human control over weapons effects in our understanding is part of the basis of the definition of indiscriminate weapons . For example , the ICRC has made it clear also that in defining what constitutes an indiscriminate weapons there are two criteria that are frequently referred to . Number one , whether the weapon is capable of being targeted or directed at a military objective and number two , whether its effects can be limited or controlled . Indeed , there are various provisions within existing IHL in additional protocol 1 to the Geneva Conventions , for example , if you look at Article 51 , subsection 4 , subsection B , if you look at Article 51 , subsection 4 , subsection C , where the question of controlling the effects of a weapon are emphasized as part of the definition of what constitutes an indiscriminate weapon . The same is contained also in rule 12 of customary international humanitarian law in this regard . And , of course , there have been a number of UN General Assembly resolutions going way back where , for example , the question of uncontrollability of effects of a weapon makes it an indiscriminate weapon . Indeed , as a last point on this , for example , in cases before the International Court of Justice , the nuclear weapons case , various states , some of them were in this meeting were able to emphasize the point again that the question of uncontrollability of effects of a weapon makes it indiscriminate . So the concern here is the idea where we are saying it is not always possible to control effects of a weapon . I do not think at least in our view that is the correct characterization of the current position of the law . I would like to thank you for your intervention .",Non-applicable,No
MEXICO,17:26:42,2024-03-05,0:07:03,"Thank you very much , Chair . And to begin , I would like to express my apologies because due to the very charged disarmament agenda I was unable to be present this morning and I arrived late to this afternoon's session . So I can not offer very interactive comments given that I was unable to listen to all Delegations unfortunately . But I will make a presentation about some of these items from our perspective . I would like to begin by mentioning the seminar report of Christopher Hines , special rapporteur on extrajudicial executions who in 2013 already , and we believe this is still quite relevant for our discussions today , said that autonomous weapon systems raise serious and far reaching concerns for the protection of people and lives in both peace and war . This includes a question about the ways in which they can be programmed in order to meet the IHL requirements as well as the protection standards of life under international human rights law . Obviously , this perspective recognizes the necessary interaction between the IHL system and international human rights law which is backed by its jurisprudence and the impossibility of creating a false division in the way in which they ought to be considered and so for our Delegation , there is no question that any weapon system must be developed , deployed and used in keeping with IHL but also with international human rights law , international criminal law and the law and international responsibility in the UN charter . Though Mexico considers that significant human control is an implicit component in IHL , we also take into account existing differences , those that we have been discussing for a decade . So we appreciate the presentation of your list , the various components and elements that would make laws incompatible with IHL . However , we believe along with ICRC and Austria and others that the goal is not simply to have a list of the prohibitions or general applicable regulations but rather to define the specific relevant aspects to ensure that its implementation is compatible bearing in mind the specific elements of autonomy . And so in that regard , we agree with the list that reiterates already existing prohibitions of IHL , particularly those that by their nature are prohibited given that they cannot be used in keeping with existing limitations . For example , being unable to distinguish between military and civilian targets , between combatants and civilian population , between active combatants and persons or to combat , those that cause superfluous damage or unnecessary harm or those that have effects that cannot be limited in keeping with the fundamental principles of IHL , specifically on grounds of distinction and proportionality . Ten years of studying this subject has also shown that these prohibitions given autonomous technologies raise some very essential difficulties bearing in mind that these determinations take place in very complicated contexts and differentiated contexts which require a fundamental human assessment . So we agree with Pakistan and others in that regard who say that we need a more subtle approach , one that would identify specific and indispensable elements in order to be able to meet these general obligations . From our standpoint , some of them include that the development and use of autonomous weapons systems that cannot be controlled , I will start again , to prohibit the use and development of autonomous systems that cannot be controlled by humans for which they are limited to cognitive and epistemological limitations in addition to being subjected to different types of bias , for example , those arising from the source of information being employed or algorithmic bias . Two , that the development and use of autonomous weapons systems whose programming allows for the removal of human control over the critical functions related to the selection of targets , the involvement and use of force , the development and use of autonomous weapons systems whose effects do not meet the criteria of predictability and whether it is explainable for the operators . Or four , the development and use of autonomous weapons systems that were not subjected to a legal assessment in keeping with the obligations under Article 36 of the additional protocol 1 in customary law . Now , the simple involvement of a human in the selection operation and the involvement in the use of force does not resolve in and of itself the compatibility risks with IHL given that it seems to not involve some fundamental components of the human component . There must be a guarantee that there are proper understanding of the limitations of their use , even spatial and temporal limitations and a decision that is taken must take place when they know the operational context through a sufficient knowledge of the situational environment . It must take the necessary precautions in carrying out operations in order to ensure that parameters of the mission do not change without human assessment and that it allows for constant oversight to guarantee intervention when needed , particularly in order to interrupt and deactivate the system during the operational stage . And lastly , that the guarantee that human involvement be substantive , not just in name only . Now , all of these are elements that as has been said will require further consideration in future debates . And lastly , we would like to reiterate as we said yesterday when we agree with the ICRC and others on the relevance of the ethical perspective , deontologically speaking and under the criterion of human dignity , which is part and parcel inherently implicit in IHL and international human rights law . Thank you .",Latin American and Caribbean States,Yes
GERMANY,17:41:40,2024-03-05,0:01:01,"The use of the system can be incompatible with IHL in specific contexts . There are various conceivable contexts in which the use of a system may be contrary to international law . However , abstract enumerations and categorizations are not conceivable or appropriate here in our view . It is clear that the use of laws in densely populated areas poses other challenges than at C However , it can be inferred that the use of laws in densely populated areas is incompatible with IHL . Many of the different factors as enumerated under subbullet 1 , 4 and their mutual relationship matter . In Germany's view , the subbullets 5 to 8 also contain valuable elements in order to ensure appropriate human control over the life cycle of laws and on which further elaboration of the text can build . I will thank you for your views on the aspect of the context .",Western European and other States,Yes
INTERNATIONAL COMMITTEE FOR ROBOT ARMS CONTROL,17:42:56,2024-03-05,0:01:17,"Once again , thank you very much , Chair . Just two points . The first one , it is on the question maybe of dividing these bullet points . Number one , the point which I think we want to make is that perhaps we need to clearly state that for laws that are illegal per se , those ones that are prohibited because they are not compatible with IHL in that regard , there is no context with the IHL in that regard , there is no context with IHL in that regard , with those particular laws . There is no context within which they can be used . So that would be the first point . Regarding the others which perhaps can be regulated , I just wanted to make a short comment on the question of I can not see what bullet number it is , but the ones that refer to good faith , we are not sure exactly where , for example , under IHL , the question of good faith and due diligence can be located . I think I would be interested to hear from those perhaps suggesting that terminology if they can explain further the question of good faith .",Non-applicable,No
